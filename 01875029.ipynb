{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jWAqfqlcc5O4",
   "metadata": {
    "id": "jWAqfqlcc5O4"
   },
   "source": [
    "# DGL CW1\n",
    "Hi everyone, good luck on the first CW of the DGL course. Please do not hesitate to ask your questions on EdStem if you have any.\n",
    "\n",
    "## Questions\n",
    "1. Centrality-based Graph Classification (25 points)\n",
    "2. Implementation of GraphSAGE with Node Sampling (30 points)\n",
    "3. Attention-based aggregation in node classification (30 points)\n",
    "4. Propagation rule integrating edge features/embeddings (15 points)\n",
    "5. Bonus Questions (5 points)\n",
    "\n",
    "## Submission Instructions\n",
    "For submission, you only need to submit your Jupyter Notebook file named \"CID.ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3JNrkaurjfpM",
   "metadata": {
    "id": "3JNrkaurjfpM"
   },
   "source": [
    "# Required Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vZCmHCdxjn4I",
   "metadata": {
    "id": "vZCmHCdxjn4I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.1 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (4.66.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dgl) (0.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->dgl) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->dgl) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
      "Requirement already satisfied: torch>=2 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchdata>=0.5.0->dgl) (2.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->dgl) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\taow\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\taow\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "DBqqR7fPjqKq",
   "metadata": {
    "id": "DBqqR7fPjqKq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Data handling, numerical processing, and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning, neural network modules, and metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Graph processing\n",
    "import networkx as nx\n",
    "\n",
    "# DGL and datasets\n",
    "from dgl.data import PPIDataset, CoraGraphDataset\n",
    "\n",
    "# Set a fixed random seed for reproducibility across multiple libraries\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Check for CUDA (GPU support) and set device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # For multi-GPU setups\n",
    "    # Additional settings for ensuring reproducibility on CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LQ7SGGtic5O6",
   "metadata": {
    "id": "LQ7SGGtic5O6"
   },
   "source": [
    "# 1) Centrality-based Graph Classification (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DeiwfbLOc5O7",
   "metadata": {
    "id": "DeiwfbLOc5O7"
   },
   "source": [
    "## Part 1: Implementing and Analyzing PageRank Centrality\n",
    "\n",
    "### Objective\n",
    "The goal of this task is to enhance your comprehension of the PageRank centrality algorithm through hands-on implementation. You are tasked with coding the algorithm from the ground up and applying it to two specific graphs, named $G1$ and $G2$. Following the application, you will analyze and compare the PageRank distributions between these two graphs.\n",
    "\n",
    "### Total Points: 10\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### 1. **Implement the PageRank Algorithm**\n",
    "\n",
    "- **Initialization**: Assign an equal PageRank to every node initially. For a graph containing $N$ nodes, each node's starting PageRank is $1/N$.\n",
    "\n",
    "- **Calculation**: Update each node's PageRank by employing the formula:\n",
    "  $$PR(p_i) = \\frac{1-d}{N} + d \\sum_{p_j \\in M(p_i)} \\frac{PR(p_j)}{L(p_j)}$$\n",
    "  where:\n",
    "  - $PR(p_i)$ denotes the PageRank of page $p_i$,\n",
    "  - $d$ represents the damping factor, usually set at 0.85,\n",
    "  - $N$ is the total count of nodes within the graph,\n",
    "  - $M(p_i)$ encompasses the set of nodes linking to $p_i$,\n",
    "  - $L(p_j)$ signifies the number of outbound links from node $p_j$.\n",
    "\n",
    "- **Convergence**: Continuously recalculate until the PageRank values reach a stable condition, evidenced by negligible changes between successive iterations.\n",
    "\n",
    "#### 2. **Pre-defined Graphs G1 and G2**\n",
    "\n",
    "- You have access to two graphs, $G1$ and $G2$, within your environment. These will serve as your experimental subjects for the PageRank algorithm application.\n",
    "\n",
    "#### 3. **Calculate PageRank Values**\n",
    "\n",
    "- Implement your PageRank algorithm on both $G1$ and $G2$ to determine the PageRank values for their respective nodes.\n",
    "\n",
    "#### 4. **Visualize the Results**\n",
    "\n",
    "- Create plots to showcase the PageRank value distributions for $G1$ and $G2$. Apply a transparent blue overlay for $G1$ and a transparent red for $G2$, facilitating an effortless comparison.\n",
    "\n",
    "#### 5. **Analysis**\n",
    "\n",
    "- **Reflect** upon the PageRank distribution variances between $G1$ and $G2$, pondering over:\n",
    "  - The impact of $G1$ and $G2$ structures on their PageRank distributions.\n",
    "  - Whether the PageRank values are more clustered or dispersed in one graph relative to the other.\n",
    "  - The presence of any nodes that emerge as notably more central within their graphs.\n",
    "\n",
    "### Comment Section\n",
    "\n",
    "- **Discuss** the insights and observations derived from juxtaposing the PageRank distributions of $G1$ and $G2$. Highlight any discerned patterns or anomalies, and deliberate on how each graph's inherent structure could elucidate these findings.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b68a8c1",
   "metadata": {},
   "source": [
    "Answer Inverse Power Law (Scale free networks)????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0c276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def initialize_page_rank(graph):\n",
    "    \"\"\"\n",
    "    Initialize the PageRank scores for all nodes in a graph.\n",
    "    \n",
    "    #TODO: Implement this function to initialize PageRank scores for each node.\n",
    "    - Assume each node has an equal initial PageRank value.\n",
    "    - The function takes a graph as input and returns a dictionary with nodes as keys and initial PageRank scores as values.\n",
    "    \"\"\"\n",
    "    N = len(graph)\n",
    "    scores = {node: 1/N for node in graph.keys()}\n",
    "    \n",
    "    return scores\n",
    "    \n",
    "\n",
    "def calculate_page_rank(graph, d=0.85, max_iterations=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Calculate the PageRank scores for all nodes in the graph using the iterative PageRank formula.\n",
    "    \n",
    "    #TODO: Implement this function to calculate the PageRank scores.\n",
    "    - Use the iterative PageRank algorithm with the damping factor `d`.\n",
    "    - Continue iterating until the change in PageRank scores is below `tol` or until `max_iterations` is reached.\n",
    "    - The function returns a dictionary with nodes as keys and their PageRank scores as values.\n",
    "    \"\"\"\n",
    "    N = len(graph)\n",
    "    scores = initialize_page_rank(graph)\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        new_scores = dict.fromkeys(graph.keys(), 0)\n",
    "\n",
    "        for node in graph.keys():\n",
    "            # find predecessors\n",
    "            predecessors = [pred for pred, successors in graph.items() if node in successors]\n",
    "            # update rule \n",
    "            new_scores[node] = (1 - d) / N + d * sum([scores[p] / len(graph[p]) for p in predecessors]) \n",
    "        \n",
    "        # check convergence criteria \n",
    "        if np.allclose(list(scores.values()), list(new_scores.values()), atol=tol):\n",
    "            break\n",
    "        \n",
    "        # update new page rank scores\n",
    "        scores = new_scores\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def visualize_distributions(page_ranks_g1, page_ranks_g2):\n",
    "    \"\"\"\n",
    "    Visualizes the distributions of PageRank values for two graphs on the same histogram for comparison.\n",
    "    \n",
    "    #TODO: Implement this function to visualize the distributions of PageRank values.\n",
    "    - Use a histogram to compare the PageRank distributions of two different graphs.\n",
    "    - Customize the plot with labels, titles, and a legend.\n",
    "    \"\"\"\n",
    "    values_g1 = list(page_ranks_g1.values())\n",
    "    values_g2 = list(page_ranks_g2.values())\n",
    "\n",
    "    plt.hist(values_g1, alpha=0.5, label='Graph 1 PageRanks', bins='auto')\n",
    "    plt.hist(values_g2, alpha=0.5, label='Graph 2 PageRanks', bins='auto')\n",
    "\n",
    "    plt.title('Comparison of PageRank Distributions')\n",
    "    plt.xlabel('PageRank Value')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Generating larger graphs G1 and G2 with more complexity\n",
    "G1 = nx.fast_gnp_random_graph(100, 0.05, directed=True)\n",
    "G2 = nx.fast_gnp_random_graph(100, 0.05, directed=True)\n",
    "\n",
    "# Convert NetworkX graphs to adjacency lists\n",
    "graph_g1 = {n: list(G1.successors(n)) for n in G1.nodes()}\n",
    "graph_g2 = {n: list(G2.successors(n)) for n in G2.nodes()}\n",
    "\n",
    "#TODO: Use the `calculate_page_rank` function to calculate PageRank values for `graph_g1` and `graph_g2`.\n",
    "#TODO: Use the `visualize_distributions` function to compare the PageRank distributions of `graph_g1` and `graph_g2`.\n",
    "g1_scores = calculate_page_rank(graph_g1)\n",
    "g2_scores = calculate_page_rank(graph_g2)\n",
    "\n",
    "visualize_distributions(g1_scores, g2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64518e3",
   "metadata": {},
   "source": [
    "I have left the test script below for your ease of marking :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e57c8c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case                 | Accuracy Score \n",
      "------------------------------------------\n",
      "Simple Chain              | 9.3695326875   \n",
      "Star Graph                | 9.999996653768559\n",
      "Cycle                     | 10.0           \n",
      "Complete Graph            | 10.0           \n",
      "Graph with Sink Node      | 10.0           \n",
      "Disconnected Graph        | 9.271125       \n",
      "Large Sparse Graph        | 9.35959943387916\n",
      "------------------------------------------\n",
      "Average Accuracy          | 9.71           \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "def calculate_expected_page_rank(nx_graph):\n",
    "    \"\"\"\n",
    "    Calculate the expected PageRank values using NetworkX for comparison.\n",
    "\n",
    "    Parameters:\n",
    "        nx_graph (networkx.Graph): The NetworkX graph object.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with nodes as keys and their PageRank scores as values.\n",
    "    \"\"\"\n",
    "    return nx.pagerank(nx_graph, alpha=0.85)\n",
    "\n",
    "def compare_page_rank(student_output, expected_output):\n",
    "    \"\"\"\n",
    "    Compare the student's PageRank output with the expected output.\n",
    "\n",
    "    Parameters:\n",
    "        student_output (dict): The PageRank scores computed by the student's function.\n",
    "        expected_output (dict): The expected PageRank scores computed by NetworkX.\n",
    "\n",
    "    Returns:\n",
    "        float: The total absolute difference between the student's and expected PageRank scores.\n",
    "    \"\"\"\n",
    "    diff = sum(abs(student_output[node] - expected_output.get(node, 0)) for node in student_output)\n",
    "    return diff\n",
    "\n",
    "def grade_student_implementation(student_func, graph):\n",
    "    \"\"\"\n",
    "    Grades the student's PageRank implementation by comparing its output against expected values from NetworkX.\n",
    "\n",
    "    Parameters:\n",
    "        student_func (function): The student's PageRank function to be graded.\n",
    "        graph (dict): The graph represented as an adjacency list on which the student's function will be tested.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the accuracy score and efficiency score.\n",
    "    \"\"\"\n",
    "    nx_graph = nx.DiGraph(graph)\n",
    "    expected_output = calculate_expected_page_rank(nx_graph)\n",
    "\n",
    "    start_time = time.time()\n",
    "    student_output = student_func(graph)\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    diff = compare_page_rank(student_output, expected_output)\n",
    "    #print('diff = ', diff)\n",
    "    accuracy_score = max(0, 10 - diff)  # Adjusted accuracy scoring formula\n",
    "    efficiency_score = max(0, min(5, 5 - execution_time))  # Ensures efficiency scores are within a 0-5 range\n",
    "\n",
    "    return accuracy_score, efficiency_score\n",
    "\n",
    "def generate_test_graphs():\n",
    "    np.random.seed(42)  # Setting a seed for reproducibility\n",
    "    test_cases = {\n",
    "        \"Simple Chain\": nx.path_graph(5, create_using=nx.DiGraph()),\n",
    "        \"Star Graph\": nx.DiGraph(nx.star_graph(4)),  # Convert to DiGraph after creation\n",
    "        \"Cycle\": nx.cycle_graph(5, create_using=nx.DiGraph()),\n",
    "        \"Complete Graph\": nx.complete_graph(5, create_using=nx.DiGraph()),\n",
    "        \"Graph with Sink Node\": nx.DiGraph([(0, 1), (1, 2), (2, 2)]),\n",
    "        \"Disconnected Graph\": nx.disjoint_union_all([nx.path_graph(3, create_using=nx.DiGraph()),\n",
    "                                                     nx.path_graph(3, create_using=nx.DiGraph())]),\n",
    "        \"Large Sparse Graph\": nx.fast_gnp_random_graph(100, 0.01, directed=True, seed=np.random.randint(1000))\n",
    "    }\n",
    "    return test_cases\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_graphs = generate_test_graphs()\n",
    "    accuracies = []\n",
    "    for name, graph in test_graphs.items():\n",
    "        graph_adj_list = {n: list(graph.successors(n)) for n in graph.nodes()}\n",
    "        accuracy, _ = grade_student_implementation(calculate_page_rank, graph_adj_list)\n",
    "        accuracies.append((name, accuracy))\n",
    "    \n",
    "    # Print the accuracies in a tabular format\n",
    "    print(f\"{'Test Case':<25} | {'Accuracy Score':<15}\")\n",
    "    print(\"-\" * 42)  # Adjust the length based on your column widths\n",
    "    for name, accuracy in accuracies:\n",
    "        print(f\"{name:<25} | {accuracy:<15}\")\n",
    "\n",
    "    # Calculate and print the average accuracy score\n",
    "    average_accuracy = sum(score for _, score in accuracies) / len(accuracies)\n",
    "    print(\"-\" * 42)  # Separator for the average\n",
    "    print(f\"{'Average Accuracy':<25} | {average_accuracy:<15.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b005c",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Graph Convolutional Networks (GCN) for Graph Classification\n",
    "\n",
    "### Objective\n",
    "\n",
    "Your main objective is to modify the degree-based propagation rule using the following topological measures for normalization:\n",
    "1. **PageRank Centrality**: Utilize the PageRank centrality implementation from Part 1.\n",
    "2. **Betweenness Centrality**: Implement normalization using Betweenness centrality, which can be calculated using NetworkX.\n",
    "3. **Clustering Coefficient**: Implement normalization using the Clustering coefficient, available through NetworkX.\n",
    "\n",
    "For each normalization technique, you will develop a separate GCN model, resulting in four different GNN models including the original degree-based model.\n",
    "\n",
    "### Total Points: 15\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions\n",
    "\n",
    "#### 1. **Implement a 2-Layer GCN**\n",
    "- **Graph Representation**: Begin with the simple node degree normalization for your initial GCN implementation. Specifically, employ the normalization technique $D^{-1}A$ where $D$ is the degree matrix and $A$ is the adjacency matrix of the graph.\n",
    "- **GCN Propagation Rule**: Implement the GCN layer using the updated propagation rule:\n",
    "  $$H^{(l+1)} = \\sigma(D^{-1}AH^{(l)}W^{(l)})$$\n",
    "  Here, $H^{(l)}$ represents the node features at layer $l$, $W^{(l)}$ is the weight matrix at layer $l$, and $\\sigma$ denotes a non-linear activation function, such as ReLU.\n",
    "- **Architecture**: Design your GCN with two convolutional layers following this propagation rule. Conclude with a Mean Pooling layer to aggregate node embeddings for graph-level prediction.\n",
    "- **Prediction Head**: Develop a prediction head that processes the pooled graph representation to classify the graph.\n",
    "\n",
    "#### 2. **Topological Measures for Normalization**\n",
    "Adapt the degree-based propagation rule to incorporate the following topological measures:\n",
    "- **PageRank Centrality**: Leverage the PageRank centrality implementation from Part 1.\n",
    "- **Betweenness Centrality and Clustering Coefficient**: Use NetworkX to compute these centrality measures for each node, applying them as normalization factors in the GCN propagation rule.\n",
    "\n",
    "#### 3. **Data Preparation**\n",
    "- Ensure the train and test sets are fixed to guarantee consistent evaluation across the different normalization techniques.\n",
    "\n",
    "#### 4. **Model Training and Evaluation**\n",
    "- Independently train a GCN model for each normalization technique.\n",
    "- Assess the performance of each model, focusing on accuracy, sensitivity, and specificity.\n",
    "\n",
    "#### 5. **Analysis of Embedding Distributions and Classification Results**\n",
    "- **Embedding Distributions**: Employ PCA to reduce the dimensionality of embeddings obtained from the final layer (Layer 2) of each GCN model, and visualize these distributions.\n",
    "- **Classification Results**: Contrast the accuracy, sensitivity, and specificity results among the four models.\n",
    "\n",
    "### Comment Section\n",
    "\n",
    "Engage in discussion on the following topics based on your analysis:\n",
    "- **Comparative Analysis**: Examine how the embedding distributions and classification outcomes differ with each normalization technique.\n",
    "- **Interpretation of Results**: Reflect on the performances of GCN models under different topological normalizations. Consider how PageRank centrality, betweenness centrality, and clustering coefficient influence the embeddings and classification capabilities of the models.\n",
    "\n",
    "Delve into the reasons behind the performances observed and theorize how the distinct topological characteristics of graphs may affect GCN model efficacy. Ponder the impact of each normalization method on feature propagation within the network and its capacity to harness the structural information of the graph for classification purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedd480",
   "metadata": {},
   "source": [
    "## 1.1 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8debb0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_random_molecule_graph(num_atoms=9, num_bonds=12):\n",
    "    \"\"\"\n",
    "    Creates a random molecular graph with a specified number of atoms and bonds.\n",
    "\n",
    "    Args:\n",
    "        num_atoms (int): The number of atoms in the molecule.\n",
    "        num_bonds (int): The number of bonds between atoms in the molecule.\n",
    "\n",
    "    Returns:\n",
    "        (nx.Graph, list): A tuple containing the generated molecular graph and the list of atom labels.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    atom_labels = [f\"{i}:{random.choice(['H', 'C', 'O'])}\" for i in range(num_atoms)]\n",
    "    G.add_nodes_from(atom_labels)\n",
    "\n",
    "    for _ in range(num_bonds):\n",
    "        atom1, atom2 = random.choice(atom_labels), random.choice(atom_labels)\n",
    "        while atom1 == atom2 or G.has_edge(atom1, atom2):\n",
    "            atom1, atom2 = random.choice(atom_labels), random.choice(atom_labels)\n",
    "        G.add_edge(atom1, atom2)\n",
    "\n",
    "    return G, atom_labels\n",
    "\n",
    "def classify_molecule(G):\n",
    "    \"\"\"\n",
    "    Classifies a molecule into type 1 or type 2 based on more complex criteria (without considering nitrogen).\n",
    "\n",
    "    Args:\n",
    "        G (nx.Graph): The molecular graph.\n",
    "\n",
    "    Returns:\n",
    "        int: The type of molecule (0 or 1).\n",
    "    \"\"\"\n",
    "    atom_labels = list(G.nodes)\n",
    "    num_carbon = sum(1 for label in atom_labels if label.endswith(\":C\"))\n",
    "    num_oxygen = sum(1 for label in atom_labels if label.endswith(\":O\"))\n",
    "    num_hydrogen = sum(1 for label in atom_labels if label.endswith(\":H\"))\n",
    "    num_bonds = len(G.edges)\n",
    "\n",
    "    # Define more complex criteria for classification\n",
    "    if num_oxygen >= 2 and num_hydrogen >= 3 and num_carbon >= 2 and num_bonds >= 4:\n",
    "        return 1\n",
    "    elif num_oxygen >= 1 and num_carbon >= 3 and num_hydrogen >= 2 and num_bonds >= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "def generate_balanced_molecule_dataset(num_samples_per_type):\n",
    "    \"\"\"\n",
    "    Generates a balanced dataset of random molecule graphs.\n",
    "\n",
    "    Args:\n",
    "        num_samples_per_type (int): The number of samples per molecule type.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, each containing a graph, its atom labels, and its classification.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    while len(dataset) < num_samples_per_type * 2:\n",
    "        G, atom_labels = create_random_molecule_graph()\n",
    "        classification = classify_molecule(G)\n",
    "        if classification in [0, 1]:\n",
    "            dataset.append((G, atom_labels, classification))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def graph_to_tensors(G, atom_labels, normalization_func=None):\n",
    "    \"\"\"\n",
    "    Converts a networkx graph of a molecule into tensor representations, with optional adjacency matrix normalization.\n",
    "\n",
    "    Args:\n",
    "        G (nx.Graph): The molecular graph.\n",
    "        atom_labels (list): List of atom labels in the molecule.\n",
    "        normalization_func (callable, optional): Function to normalize the adjacency matrix.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the tensor representation of atom types (X) and (optionally normalized) adjacency matrix (A).\n",
    "    \"\"\"\n",
    "    atom_types = {'H': [1, 0, 0], 'C': [0, 1, 0], 'O': [0, 0, 1]}\n",
    "    X = torch.tensor([atom_types[node.split(':')[1]] for node in atom_labels], dtype=torch.float)\n",
    "\n",
    "    N = len(atom_labels)\n",
    "    A = torch.zeros((N, N), dtype=torch.float)\n",
    "    for i, j in G.edges:\n",
    "        idx1 = atom_labels.index(i)\n",
    "        idx2 = atom_labels.index(j)\n",
    "        A[idx1, idx2] = 1\n",
    "        A[idx2, idx1] = 1\n",
    "\n",
    "    if normalization_func:\n",
    "        A = normalization_func(G, A)  # Apply normalization if provided\n",
    "\n",
    "    return X, A\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for handling molecular graphs. Each sample in the dataset represents a molecule,\n",
    "    characterized by its graph structure and atom features, along with a classification label (e.g., for binary classification tasks).\n",
    "\n",
    "    The dataset initializes with a list of molecular data and optionally applies a normalization function to the adjacency matrix\n",
    "    of each molecule's graph. This normalization can be crucial for certain graph neural network models, affecting how the model\n",
    "    interprets the connectivity and flow of information through the graph.\n",
    "\n",
    "    Attributes:\n",
    "        dataset (list): A list of tuples, where each tuple corresponds to a molecule and contains:\n",
    "                        - A graph representation of the molecule (e.g., a `networkx` graph).\n",
    "                        - Atom labels or features as a list or array.\n",
    "                        - A classification label for the molecule.\n",
    "        normalization_func (callable, optional): A function that takes an adjacency matrix (and potentially a graph) as input\n",
    "                        and returns a normalized adjacency matrix. This can be any normalization technique, such as degree normalization,\n",
    "                        PageRank-based normalization, etc.\n",
    "\n",
    "    The class provides two main methods as part of the PyTorch `Dataset` interface:\n",
    "    - `__len__` returns the number of items in the dataset.\n",
    "    - `__getitem__` retrieves a single item from the dataset by index, applying the normalization function if provided.\n",
    "\n",
    "    #TODO: Implement the `__init__` method to initialize the dataset with the given list and normalization function.\n",
    "    - Store the provided dataset list and normalization function as instance attributes.\n",
    "\n",
    "    #TODO: Implement the `__len__` method to return the size of the dataset.\n",
    "    - This method should simply return the length of the dataset list.\n",
    "\n",
    "    #TODO: Implement the `__getitem__` method to fetch and preprocess a single graph representation from the dataset.\n",
    "    - Extract the graph `G`, atom labels `atom_labels`, and classification `classification` for the specified index `idx`.\n",
    "    - Convert the graph `G` and `atom_labels` into tensor formats suitable for graph neural networks. This often involves creating a feature matrix `X` for nodes and an adjacency matrix `A`. Use the `graph_to_tensors` function (to be implemented separately by the student) for this conversion. Apply the `normalization_func` to the adjacency matrix if provided.\n",
    "    - Convert the `classification` label into a tensor of type `torch.long`.\n",
    "    - Return the feature matrix `X`, the (optionally normalized) adjacency matrix `A`, and the label tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, normalization_func=None):\n",
    "        #TODO: Initialize the dataset and the normalization function.\n",
    "        self.dataset = dataset\n",
    "        self.normalization_func = normalization_func\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        #TODO: Return the number of items in the dataset.\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #TODO: Process and return a single item from the dataset as tensors.\n",
    "        G, atom_labels, classification = self.dataset[idx]\n",
    "        X, A = graph_to_tensors(G, atom_labels, self.normalization_func)\n",
    "\n",
    "        return X, A, torch.tensor(classification, dtype=torch.long)\n",
    "\n",
    "\n",
    "def prepare_data_loaders(num_samples_per_type, normalization_func=None, batch_size=10):\n",
    "    \"\"\"\n",
    "    Prepares DataLoader for training and testing datasets.\n",
    "\n",
    "    Args:\n",
    "        num_samples_per_type (int): Number of samples per class to generate.\n",
    "        normalization_func (callable, optional): Normalization function to apply to adjacency matrices.\n",
    "        batch_size (int): Size of each data batch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of DataLoader: Training and testing DataLoader objects.\n",
    "    \"\"\"\n",
    "    dataset = generate_balanced_molecule_dataset(num_samples_per_type)\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    train_dataset = MoleculeDataset(train_dataset, normalization_func=normalization_func)\n",
    "    test_dataset = MoleculeDataset(test_dataset, normalization_func=normalization_func)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Your GCNLayer and GCN classes remain unchanged.\n",
    "\n",
    "# Generating a few random molecule graphs for visualization\n",
    "graphs = [create_random_molecule_graph() for _ in range(3)]\n",
    "\n",
    "# Plotting the generated graphs\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, (G, atom_labels) in enumerate(graphs):\n",
    "    pos = nx.spring_layout(G)  # Using spring layout for visual aesthetics\n",
    "    nx.draw(G, pos, with_labels=True, ax=axes[i])\n",
    "    axes[i].set_title(f\"Molecule Graph {i+1}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ba759",
   "metadata": {},
   "source": [
    "## 1.2 Visualization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e02d5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_omega_distribution(layers, epochs):\n",
    "    \"\"\"\n",
    "    Visualizes the distribution of weights (Omega) in each GCN layer of the Graph Neural Network across different epochs using smooth KDE plots.\n",
    "\n",
    "    Args:\n",
    "        layers (list of tuples): Each tuple contains a layer's name and a list of arrays representing the layer's weights at different epochs.\n",
    "        epochs (list of int): List of epoch numbers corresponding to the weight arrays.\n",
    "\n",
    "    This function plots the kernel density estimation (KDE) of weight values for each layer across specified epochs, allowing for the observation of how weight distributions evolve during training.\n",
    "    \"\"\"\n",
    "    for layer_name, weight_arrays in layers:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i, weights in enumerate(weight_arrays):\n",
    "            omega_values = weights.flatten()  # Flatten the array to get a distribution of individual weight values\n",
    "            sns.kdeplot(omega_values, fill=True, label=f'Epoch {epochs[i]}')  # Use 'fill' for shaded KDE plots\n",
    "        plt.title(f'{layer_name} Weight Distribution Across Epochs', fontsize=16)\n",
    "        plt.xlabel('Weight Values', fontsize=12)\n",
    "        plt.ylabel('Density', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_training_losses(losses_list, normalization_names):\n",
    "    \"\"\"\n",
    "    Plots the training loss over epochs for different normalization techniques.\n",
    "\n",
    "    Args:\n",
    "        losses_list (list of lists): Each sublist contains the training losses for one normalization technique over all epochs.\n",
    "        normalization_names (list of str): Names of the normalization techniques used.\n",
    "\n",
    "    This function creates a line plot for each normalization technique's training loss over epochs, facilitating comparison of their performance.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, train_losses in enumerate(losses_list):\n",
    "        plt.plot(range(1, len(train_losses) + 1), train_losses, label=f'{normalization_names[i]} Normalization')\n",
    "    plt.title('Training Loss Over Epochs for Different Normalization Techniques', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metric_bar_charts(names, metric_values, metric_names):\n",
    "    \"\"\"\n",
    "    Creates bar charts for different evaluation metrics across various normalization techniques.\n",
    "\n",
    "    Args:\n",
    "        names (list of str): Names of the normalization techniques.\n",
    "        metric_values (list of lists): Each sublist contains the values of a metric for each normalization technique.\n",
    "        metric_names (list of str): Names of the metrics being plotted.\n",
    "\n",
    "    This function plots a bar chart for each provided metric, comparing the performance of different normalization techniques,\n",
    "    with y-axis limits dynamically adjusted to emphasize differences while capping at 1.\n",
    "    \"\"\"\n",
    "    num_metrics = len(metric_names)\n",
    "    num_rows = num_cols = int(math.ceil(math.sqrt(num_metrics)))\n",
    "\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12 * num_cols, 8 * num_rows))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    for i, metric_name in enumerate(metric_names):\n",
    "        ax = axes.flatten()[i] if num_metrics > 1 else axes\n",
    "\n",
    "        # Create DataFrame for seaborn\n",
    "        data = pd.DataFrame({\n",
    "            'Normalization Technique': np.repeat(names, len(metric_values[i])),\n",
    "            metric_name: np.concatenate([metric_values[i] for _ in names])\n",
    "        })\n",
    "\n",
    "        sns.barplot(x='Normalization Technique', y=metric_name, data=data, ax=ax, alpha=0.75)\n",
    "\n",
    "        # Dynamically adjust the y-axis limits\n",
    "        min_val = min(data[metric_name]) * 0.9  # Start slightly below the smallest value for better visibility\n",
    "        max_val = 1  # Ensuring the upper limit is 1\n",
    "        ax.set_ylim([min_val, max_val])\n",
    "\n",
    "        ax.set_xlabel('Normalization Technique', fontsize=14)\n",
    "        ax.set_ylabel(f'{metric_name} Value', fontsize=14)\n",
    "        ax.set_title(f'Comparison of {metric_name}', fontsize=16)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=12)\n",
    "        ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "        # Add text labels above bars\n",
    "        for p, value in zip(ax.patches, np.concatenate([metric_values[i] for _ in names])):\n",
    "            ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{value:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Hide unused subplots if the number of metrics is less than the number of subplot positions\n",
    "    for i in range(num_metrics, num_rows * num_cols):\n",
    "        if num_rows * num_cols == 1:\n",
    "            break\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_embeddings(model, loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Extracts embeddings from a model given a data loader.\n",
    "\n",
    "    #TODO: Implement this function to extract embeddings from the provided model using data from the loader.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Initialize lists or arrays to store embeddings and labels.\n",
    "    - Iterate over batches of data from the loader, ensuring to move the data to the specified device.\n",
    "    - For each batch, use the model to compute embeddings. If the model requires specific inputs (e.g., features and adjacency matrix), ensure they are correctly passed.\n",
    "    - Apply necessary post-processing on embeddings (e.g., mean pooling) and convert them to a suitable format (e.g., numpy array) for further analysis or visualization.\n",
    "    - Collect and store the labels associated with each embedding for potential use in tasks like visualization or analysis.\n",
    "    - Return the embeddings and labels as a tuple. Ensure embeddings are in a continuous array format suitable for analysis.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model from which to extract embeddings.\n",
    "        loader (DataLoader): DataLoader providing batches of data for embedding extraction.\n",
    "        device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements. The first is a numpy array of embeddings, and the second is a list of labels associated with each embedding.\n",
    "\n",
    "    Note: This function should handle device placement (CPU or GPU) for both the data and model, and ensure gradients are not computed to optimize memory and compute resources.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    embeddings = [] \n",
    "    labels = []  # Capture labels for color differentiation in PCA plots\n",
    "    with torch.no_grad(): \n",
    "        for X, A, label in loader:\n",
    "            X, A = X.to(device), A.to(device)\n",
    "            emb = model(X, A, return_embedding=True)\n",
    "            emb_mean_pooled = emb.mean(dim=1).cpu().numpy()\n",
    "            embeddings.append(emb_mean_pooled)\n",
    "            labels.extend(label.cpu().numpy())  # Store labels \n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    return embeddings, labels\n",
    "    \n",
    "\n",
    "def apply_pca_and_visualize_all_sns(embeddings_list, titles, labels_list):\n",
    "    \"\"\"\n",
    "    Applies PCA to reduce dimensionality of embeddings and visualizes them using scatter plots.\n",
    "\n",
    "    Args:\n",
    "        embeddings_list (list of np.ndarray): List of embeddings arrays to be visualized.\n",
    "        titles (list of str): Titles for each subplot, typically representing the condition or category of the embeddings.\n",
    "        labels_list (list of np.ndarray): List of label arrays corresponding to the embeddings for coloring the points.\n",
    "\n",
    "    This function reduces embeddings to two principal components using PCA and plots them, coloring points by their labels to distinguish between categories.\n",
    "    \"\"\"\n",
    "    sns.set(style='whitegrid')\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, (embeddings, title, labels) in enumerate(zip(embeddings_list, titles, labels_list)):\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_embeddings = pca.fit_transform(embeddings)\n",
    "        df = pd.DataFrame(data=pca_embeddings, columns=['PCA1', 'PCA2'])\n",
    "        df['Label'] = labels  # Add labels for coloring\n",
    "\n",
    "        sns.scatterplot(ax=axs[i], x='PCA1', y='PCA2', hue='Label', data=df, palette='viridis', alpha=0.7).set_title(title)\n",
    "        axs[i].set_xlabel('PCA Component 1')\n",
    "        axs[i].set_ylabel('PCA Component 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793cd23",
   "metadata": {},
   "source": [
    "## 1.3 Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ecd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a single Graph Convolutional Layer.\n",
    "\n",
    "    #TODO: Implement a GCN layer that performs graph convolution. This layer should first apply a linear transformation\n",
    "    to the node features and then utilize the adjacency matrix to incorporate neighborhood information. You will need to\n",
    "    define and initialize a weight matrix for the linear transformation of node features.\n",
    "    \n",
    "    Attributes:\n",
    "        - Define an attribute for the weight matrix.\n",
    "\n",
    "    Args:\n",
    "        - Accept the number of input features per node.\n",
    "        - Accept the number of output features per node.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        #TODO: Initialize the weight matrix as a torch.nn.Parameter.\n",
    "        # self.in_features = in_features\n",
    "        # self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(self.in_features, self.out_features))\n",
    "        # self.beta = nn.Parameter(torch.zeros(self.out_features)) Do we need a beta??\n",
    "        self.init_parameters()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        #TODO: Implement a method to initialize the weights uniformly with a standard deviation based on layer size.\n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "\n",
    "    def forward(self, input, adjacency):\n",
    "        \"\"\"\n",
    "        Forward pass of the GCN layer.\n",
    "        \n",
    "        #TODO: Implement the forward pass method. Apply a linear transformation to the input features and then\n",
    "        use the adjacency matrix to incorporate neighborhood information. The method should return the output feature\n",
    "        matrix after graph convolution.\n",
    "        \n",
    "        Args:\n",
    "            - input: Input feature matrix where each row represents node features.\n",
    "            - adjacency: Adjacency matrix of the graph.\n",
    "        \n",
    "        Returns:\n",
    "            - Output feature matrix after applying the graph convolution.\n",
    "        \"\"\"\n",
    "        agg = torch.matmul(adjacency, input)\n",
    "        out = torch.matmul(agg, self.W) + self.beta \n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out \n",
    "    \n",
    "\n",
    "class GCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a Graph Convolutional Network (GCN) for node classification.\n",
    "\n",
    "    #TODO: Implement a GCN model for node classification. The model should consist of two GCN layers followed by a\n",
    "    global mean pooling and a fully connected layer for classification. You need to define the GCN layers and the fully\n",
    "    connected layer in the constructor.\n",
    "    \n",
    "    Args:\n",
    "        - nfeat: Number of features for each input node.\n",
    "        - nhid: Number of hidden units for each GCN layer.\n",
    "        - nclass: Number of classes (output dimension).\n",
    "    \"\"\"\n",
    "    def __init__(self, nfeat, nhid, nclass):\n",
    "        super(GCN, self).__init__()\n",
    "        #TODO: Define the first and second graph convolutional layers and the fully connected layer for classification.\n",
    "        self.gcn1 = GCNLayer(nfeat, nhid)\n",
    "        self.gcn2 = GCNLayer(nhid, nhid)\n",
    "        self.fc = nn.Linear(nhid, nclass)\n",
    "        self.pooling_fn = lambda x: torch.mean(x, dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, return_embedding=False):\n",
    "        \"\"\"\n",
    "        Forward pass of the GCN.\n",
    "        \n",
    "        #TODO: Implement the forward pass. Apply two GCN layers with ReLU activation, perform global mean pooling,\n",
    "        and then use a fully connected layer for classification. If `return_embedding` is True, return the embedding\n",
    "        from the second GCN layer before classification.\n",
    "        \n",
    "        Args:\n",
    "            - x: Input feature matrix where each row is the feature vector of a node.\n",
    "            - adj: Adjacency matrix of the graph.\n",
    "            - return_embedding: If True, returns the embedding from the second GCN layer before classification.\n",
    "        \n",
    "        Returns:\n",
    "            - The output appropriate for your chosen loss function if return_embedding is False, otherwise\n",
    "              returns the embeddings from the second GCN layer.\n",
    "        \"\"\"\n",
    "        # do we need to normalise adjacency??\n",
    "\n",
    "        H1 = self.gcn1(x, adj)\n",
    "        # print(f'H1 has shape {H1.shape}')\n",
    "        H2 = self.gcn2(H1, adj)\n",
    "        # print(f'H2 has shape {H2.shape}')\n",
    "\n",
    "        # return the embeddings before global mean pooling if True  \n",
    "        if return_embedding:\n",
    "            return H2 \n",
    "        \n",
    "        H2_pooled = self.pooling_fn(H2)\n",
    "        # print(f'H2_pooled has shape {H2_pooled.shape}')\n",
    "        out = self.fc(H2_pooled)\n",
    "        # print(f'Out has shape {out.shape}')\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a96b83",
   "metadata": {},
   "source": [
    "## 1.4 Normalization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dec72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_degree_matrix_normalization(G, adjacency):\n",
    "    \"\"\"\n",
    "    Computes the degree matrix normalization D^-1 * A for the given graph.\n",
    "\n",
    "    #TODO: Implement this function to normalize the adjacency matrix by the inverse degree of each node.\n",
    "    - Calculate the degree for each node.\n",
    "    - Compute the inverse degree matrix D^-1.\n",
    "    - Normalize the adjacency matrix using D^-1 * A.\n",
    "    - Ensure to handle cases with isolated nodes by adding a small epsilon to the degrees to prevent division by zero.\n",
    "    - Convert and return the normalized adjacency matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-5 # Small constant to avoid division by zero \n",
    "    D_inv = torch.diag(1.0 / (epsilon + torch.sum(adjacency, dim=0))) \n",
    "    A_hat = D_inv.matmul(adjacency)\n",
    "    return A_hat\n",
    "\n",
    "\n",
    "def compute_pagerank_normalization(G, adjacency):\n",
    "    \"\"\"\n",
    "    Normalizes the adjacency matrix using PageRank centrality values.\n",
    "\n",
    "    #TODO: Implement this function to apply PageRank normalization on the adjacency matrix.\n",
    "    - Compute PageRank values for each node in the graph.\n",
    "    - Create a diagonal matrix with PageRank values.\n",
    "    - Normalize the adjacency matrix using the PageRank diagonal matrix.\n",
    "    - Convert and return the normalized adjacency matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    graph = {n: list(G.neighbors(n)) for n in G.nodes()}\n",
    "    scores = calculate_page_rank(graph)\n",
    "    D_inv = torch.diag(1.0 / torch.tensor(list(scores.values())))\n",
    "    A_hat = D_inv.matmul(adjacency)\n",
    "    # Add epsilon?? Probably not \n",
    "    # DOES NOT MENTION INVERSE ANYWHERE\n",
    "    return A_hat\n",
    "\n",
    "\n",
    "def compute_betweenness_normalization(G, adjacency):\n",
    "    \"\"\"\n",
    "    Normalizes the adjacency matrix using Betweenness centrality values.\n",
    "\n",
    "    #TODO: Implement this function to utilize Betweenness centrality for adjacency matrix normalization.\n",
    "    - Calculate Betweenness centrality for each node.\n",
    "    - Construct a diagonal matrix using the centrality values.\n",
    "    - Apply this matrix to normalize the adjacency matrix.\n",
    "    - Convert and return the normalized adjacency matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-5 # Small constant to avoid division by zero \n",
    "    scores = nx.betweenness_centrality(G)\n",
    "    D_inv = torch.diag(1.0 / (epsilon + torch.tensor(list(scores.values()))))\n",
    "    A_hat = D_inv.matmul(adjacency)\n",
    "    return A_hat\n",
    "\n",
    "\n",
    "def compute_clustering_coefficient_normalization(G, adjacency):\n",
    "    \"\"\"\n",
    "    Normalizes the adjacency matrix using Clustering coefficient values.\n",
    "\n",
    "    #TODO: Implement this function to leverage Clustering coefficients for adjacency matrix normalization.\n",
    "    - Compute the Clustering coefficient for each node.\n",
    "    - Form a diagonal matrix with these coefficients.\n",
    "    - Normalize the adjacency matrix using this coefficient matrix.\n",
    "    - Convert and return the normalized adjacency matrix as a PyTorch tensor.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-5 # Small constant to avoid division by zero \n",
    "    scores = nx.clustering(G)\n",
    "    D_inv = torch.diag(1.0 / (epsilon + torch.tensor(list(scores.values()))))\n",
    "    A_hat = D_inv.matmul(adjacency)\n",
    "    return A_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e56d0",
   "metadata": {},
   "source": [
    "## 1.5 Training & Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0336e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, epochs=100, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the model over a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for the training data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used for model parameter updates.\n",
    "        criterion (torch.nn.Module): Loss function used for training.\n",
    "        epochs (int, optional): Number of epochs to train the model. Defaults to 100.\n",
    "        device (str, optional): The device to run the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing the average loss value for each epoch.\n",
    "\n",
    "    This function iterates over the training dataset for a given number of epochs, performing\n",
    "    forward and backward passes, and updates the model parameters. The average loss per epoch is recorded and returned.\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    loss_values = []  # Initialize a list to store the average loss per epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0  # Track total loss for each epoch\n",
    "\n",
    "        for X, A, labels in train_loader:\n",
    "            # Move data to the specified device\n",
    "            # print('Moving data to device in train_model')\n",
    "            X, A, labels = X.to(device), A.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear gradients for the next train step\n",
    "            # print('About to call the model')\n",
    "            output = model(X, A)  # Forward pass\n",
    "\n",
    "            loss = criterion(output, labels)  # Compute the loss\n",
    "            loss.backward()  # Backward pass to compute gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)  # Calculate average loss\n",
    "        loss_values.append(avg_loss)  # Append average loss to list\n",
    "\n",
    "        # Print the average loss for the current epoch\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "    return loss_values\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be evaluated.\n",
    "        test_loader (torch.utils.data.DataLoader): DataLoader for the test data.\n",
    "        device (str, optional): The device to run the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the accuracy, precision, recall, and F1 score of the model on the test dataset.\n",
    "\n",
    "    This function performs a forward pass on the test dataset to obtain the model's predictions,\n",
    "    then calculates and returns various evaluation metrics including accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    true_labels = []  # List to store actual labels\n",
    "    predictions = []  # List to store model predictions\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for X, A, labels in test_loader:\n",
    "            # Move data to the specified device\n",
    "            X, A, labels = X.to(device), A.to(device), labels.to(device)\n",
    "\n",
    "            output = model(X, A)  # Forward pass\n",
    "            _, predicted = torch.max(output.data, 1)  # Get the index of the max log-probability\n",
    "\n",
    "            true_labels += labels.tolist()  # Append actual labels\n",
    "            predictions += predicted.tolist()  # Append predicted labels\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484968ac",
   "metadata": {},
   "source": [
    "## 1.6 Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cde7dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with degree normalization...\n",
      "DataLoader batch size: 50\n",
      "Epoch 1/200, Loss: 0.6865\n",
      "Epoch 2/200, Loss: 0.6761\n",
      "Epoch 3/200, Loss: 0.6650\n",
      "Epoch 4/200, Loss: 0.6511\n",
      "Epoch 5/200, Loss: 0.6344\n",
      "Epoch 6/200, Loss: 0.6170\n",
      "Epoch 7/200, Loss: 0.5995\n",
      "Epoch 8/200, Loss: 0.5863\n",
      "Epoch 9/200, Loss: 0.5757\n",
      "Epoch 10/200, Loss: 0.5685\n",
      "Epoch 11/200, Loss: 0.5630\n",
      "Epoch 12/200, Loss: 0.5600\n",
      "Epoch 13/200, Loss: 0.5562\n",
      "Epoch 14/200, Loss: 0.5520\n",
      "Epoch 15/200, Loss: 0.5498\n",
      "Epoch 16/200, Loss: 0.5475\n",
      "Epoch 17/200, Loss: 0.5457\n",
      "Epoch 18/200, Loss: 0.5449\n",
      "Epoch 19/200, Loss: 0.5435\n",
      "Epoch 20/200, Loss: 0.5415\n",
      "Epoch 21/200, Loss: 0.5397\n",
      "Epoch 22/200, Loss: 0.5391\n",
      "Epoch 23/200, Loss: 0.5379\n",
      "Epoch 24/200, Loss: 0.5365\n",
      "Epoch 25/200, Loss: 0.5363\n",
      "Epoch 26/200, Loss: 0.5349\n",
      "Epoch 27/200, Loss: 0.5343\n",
      "Epoch 28/200, Loss: 0.5337\n",
      "Epoch 29/200, Loss: 0.5336\n",
      "Epoch 30/200, Loss: 0.5324\n",
      "Epoch 31/200, Loss: 0.5323\n",
      "Epoch 32/200, Loss: 0.5316\n",
      "Epoch 33/200, Loss: 0.5312\n",
      "Epoch 34/200, Loss: 0.5321\n",
      "Epoch 35/200, Loss: 0.5309\n",
      "Epoch 36/200, Loss: 0.5305\n",
      "Epoch 37/200, Loss: 0.5306\n",
      "Epoch 38/200, Loss: 0.5300\n",
      "Epoch 39/200, Loss: 0.5292\n",
      "Epoch 40/200, Loss: 0.5290\n",
      "Epoch 41/200, Loss: 0.5285\n",
      "Epoch 42/200, Loss: 0.5286\n",
      "Epoch 43/200, Loss: 0.5288\n",
      "Epoch 44/200, Loss: 0.5280\n",
      "Epoch 45/200, Loss: 0.5279\n",
      "Epoch 46/200, Loss: 0.5280\n",
      "Epoch 47/200, Loss: 0.5274\n",
      "Epoch 48/200, Loss: 0.5274\n",
      "Epoch 49/200, Loss: 0.5270\n",
      "Epoch 50/200, Loss: 0.5277\n",
      "Epoch 51/200, Loss: 0.5263\n",
      "Epoch 52/200, Loss: 0.5265\n",
      "Epoch 53/200, Loss: 0.5285\n",
      "Epoch 54/200, Loss: 0.5271\n",
      "Epoch 55/200, Loss: 0.5267\n",
      "Epoch 56/200, Loss: 0.5261\n",
      "Epoch 57/200, Loss: 0.5261\n",
      "Epoch 58/200, Loss: 0.5260\n",
      "Epoch 59/200, Loss: 0.5258\n",
      "Epoch 60/200, Loss: 0.5257\n",
      "Epoch 61/200, Loss: 0.5263\n",
      "Epoch 62/200, Loss: 0.5253\n",
      "Epoch 63/200, Loss: 0.5269\n",
      "Epoch 64/200, Loss: 0.5255\n",
      "Epoch 65/200, Loss: 0.5258\n",
      "Epoch 66/200, Loss: 0.5254\n",
      "Epoch 67/200, Loss: 0.5252\n",
      "Epoch 68/200, Loss: 0.5253\n",
      "Epoch 69/200, Loss: 0.5253\n",
      "Epoch 70/200, Loss: 0.5282\n",
      "Epoch 71/200, Loss: 0.5247\n",
      "Epoch 72/200, Loss: 0.5256\n",
      "Epoch 73/200, Loss: 0.5246\n",
      "Epoch 74/200, Loss: 0.5253\n",
      "Epoch 75/200, Loss: 0.5252\n",
      "Epoch 76/200, Loss: 0.5253\n",
      "Epoch 77/200, Loss: 0.5240\n",
      "Epoch 78/200, Loss: 0.5249\n",
      "Epoch 79/200, Loss: 0.5250\n",
      "Epoch 80/200, Loss: 0.5249\n",
      "Epoch 81/200, Loss: 0.5244\n",
      "Epoch 82/200, Loss: 0.5247\n",
      "Epoch 83/200, Loss: 0.5244\n",
      "Epoch 84/200, Loss: 0.5244\n",
      "Epoch 85/200, Loss: 0.5241\n",
      "Epoch 86/200, Loss: 0.5247\n",
      "Epoch 87/200, Loss: 0.5238\n",
      "Epoch 88/200, Loss: 0.5237\n",
      "Epoch 89/200, Loss: 0.5237\n",
      "Epoch 90/200, Loss: 0.5240\n",
      "Epoch 91/200, Loss: 0.5242\n",
      "Epoch 92/200, Loss: 0.5244\n",
      "Epoch 93/200, Loss: 0.5244\n",
      "Epoch 94/200, Loss: 0.5239\n",
      "Epoch 95/200, Loss: 0.5246\n",
      "Epoch 96/200, Loss: 0.5241\n",
      "Epoch 97/200, Loss: 0.5240\n",
      "Epoch 98/200, Loss: 0.5240\n",
      "Epoch 99/200, Loss: 0.5241\n",
      "Epoch 100/200, Loss: 0.5239\n",
      "Epoch 101/200, Loss: 0.5243\n",
      "Epoch 102/200, Loss: 0.5232\n",
      "Epoch 103/200, Loss: 0.5234\n",
      "Epoch 104/200, Loss: 0.5243\n",
      "Epoch 105/200, Loss: 0.5239\n",
      "Epoch 106/200, Loss: 0.5243\n",
      "Epoch 107/200, Loss: 0.5234\n",
      "Epoch 108/200, Loss: 0.5234\n",
      "Epoch 109/200, Loss: 0.5232\n",
      "Epoch 110/200, Loss: 0.5236\n",
      "Epoch 111/200, Loss: 0.5232\n",
      "Epoch 112/200, Loss: 0.5236\n",
      "Epoch 113/200, Loss: 0.5232\n",
      "Epoch 114/200, Loss: 0.5230\n",
      "Epoch 115/200, Loss: 0.5229\n",
      "Epoch 116/200, Loss: 0.5231\n",
      "Epoch 117/200, Loss: 0.5230\n",
      "Epoch 118/200, Loss: 0.5236\n",
      "Epoch 119/200, Loss: 0.5229\n",
      "Epoch 120/200, Loss: 0.5229\n",
      "Epoch 121/200, Loss: 0.5232\n",
      "Epoch 122/200, Loss: 0.5226\n",
      "Epoch 123/200, Loss: 0.5234\n",
      "Epoch 124/200, Loss: 0.5235\n",
      "Epoch 125/200, Loss: 0.5239\n",
      "Epoch 126/200, Loss: 0.5239\n",
      "Epoch 127/200, Loss: 0.5230\n",
      "Epoch 128/200, Loss: 0.5226\n",
      "Epoch 129/200, Loss: 0.5224\n",
      "Epoch 130/200, Loss: 0.5245\n",
      "Epoch 131/200, Loss: 0.5226\n",
      "Epoch 132/200, Loss: 0.5225\n",
      "Epoch 133/200, Loss: 0.5226\n",
      "Epoch 134/200, Loss: 0.5229\n",
      "Epoch 135/200, Loss: 0.5249\n",
      "Epoch 136/200, Loss: 0.5228\n",
      "Epoch 137/200, Loss: 0.5234\n",
      "Epoch 138/200, Loss: 0.5227\n",
      "Epoch 139/200, Loss: 0.5230\n",
      "Epoch 140/200, Loss: 0.5227\n",
      "Epoch 141/200, Loss: 0.5229\n",
      "Epoch 142/200, Loss: 0.5237\n",
      "Epoch 143/200, Loss: 0.5249\n",
      "Epoch 144/200, Loss: 0.5236\n",
      "Epoch 145/200, Loss: 0.5236\n",
      "Epoch 146/200, Loss: 0.5235\n",
      "Epoch 147/200, Loss: 0.5226\n",
      "Epoch 148/200, Loss: 0.5225\n",
      "Epoch 149/200, Loss: 0.5225\n",
      "Epoch 150/200, Loss: 0.5225\n",
      "Epoch 151/200, Loss: 0.5230\n",
      "Epoch 152/200, Loss: 0.5236\n",
      "Epoch 153/200, Loss: 0.5228\n",
      "Epoch 154/200, Loss: 0.5226\n",
      "Epoch 155/200, Loss: 0.5228\n",
      "Epoch 156/200, Loss: 0.5228\n",
      "Epoch 157/200, Loss: 0.5223\n",
      "Epoch 158/200, Loss: 0.5228\n",
      "Epoch 159/200, Loss: 0.5225\n",
      "Epoch 160/200, Loss: 0.5231\n",
      "Epoch 161/200, Loss: 0.5232\n",
      "Epoch 162/200, Loss: 0.5228\n",
      "Epoch 163/200, Loss: 0.5227\n",
      "Epoch 164/200, Loss: 0.5230\n",
      "Epoch 165/200, Loss: 0.5230\n",
      "Epoch 166/200, Loss: 0.5224\n",
      "Epoch 167/200, Loss: 0.5224\n",
      "Epoch 168/200, Loss: 0.5226\n",
      "Epoch 169/200, Loss: 0.5224\n",
      "Epoch 170/200, Loss: 0.5229\n",
      "Epoch 171/200, Loss: 0.5231\n",
      "Epoch 172/200, Loss: 0.5243\n",
      "Epoch 173/200, Loss: 0.5224\n",
      "Epoch 174/200, Loss: 0.5230\n",
      "Epoch 175/200, Loss: 0.5222\n",
      "Epoch 176/200, Loss: 0.5228\n",
      "Epoch 177/200, Loss: 0.5223\n",
      "Epoch 178/200, Loss: 0.5222\n",
      "Epoch 179/200, Loss: 0.5222\n",
      "Epoch 180/200, Loss: 0.5221\n",
      "Epoch 181/200, Loss: 0.5227\n",
      "Epoch 182/200, Loss: 0.5227\n",
      "Epoch 183/200, Loss: 0.5222\n",
      "Epoch 184/200, Loss: 0.5233\n",
      "Epoch 185/200, Loss: 0.5237\n",
      "Epoch 186/200, Loss: 0.5226\n",
      "Epoch 187/200, Loss: 0.5219\n",
      "Epoch 188/200, Loss: 0.5225\n",
      "Epoch 189/200, Loss: 0.5230\n",
      "Epoch 190/200, Loss: 0.5235\n",
      "Epoch 191/200, Loss: 0.5223\n",
      "Epoch 192/200, Loss: 0.5222\n",
      "Epoch 193/200, Loss: 0.5219\n",
      "Epoch 194/200, Loss: 0.5226\n",
      "Epoch 195/200, Loss: 0.5223\n",
      "Epoch 196/200, Loss: 0.5224\n",
      "Epoch 197/200, Loss: 0.5227\n",
      "Epoch 198/200, Loss: 0.5228\n",
      "Epoch 199/200, Loss: 0.5222\n",
      "Epoch 200/200, Loss: 0.5232\n",
      "Results with degree normalization - Accuracy: 0.8175, Precision: 0.8170, Recall: 0.8175, F1 Score: 0.8153\n",
      "\n",
      "Training model with pagerank normalization...\n",
      "DataLoader batch size: 50\n",
      "Epoch 1/200, Loss: 0.7320\n",
      "Epoch 2/200, Loss: 0.7320\n",
      "Epoch 3/200, Loss: 0.7320\n",
      "Epoch 4/200, Loss: 0.7320\n",
      "Epoch 5/200, Loss: 0.7320\n",
      "Epoch 6/200, Loss: 0.7320\n",
      "Epoch 7/200, Loss: 0.7320\n",
      "Epoch 8/200, Loss: 0.7320\n",
      "Epoch 9/200, Loss: 0.7320\n",
      "Epoch 10/200, Loss: 0.7320\n",
      "Epoch 11/200, Loss: 0.7320\n",
      "Epoch 12/200, Loss: 0.7320\n",
      "Epoch 13/200, Loss: 0.7320\n",
      "Epoch 14/200, Loss: 0.7320\n",
      "Epoch 15/200, Loss: 0.7320\n",
      "Epoch 16/200, Loss: 0.7320\n",
      "Epoch 17/200, Loss: 0.7320\n",
      "Epoch 18/200, Loss: 0.7320\n",
      "Epoch 19/200, Loss: 0.7320\n",
      "Epoch 20/200, Loss: 0.7320\n",
      "Epoch 21/200, Loss: 0.7320\n",
      "Epoch 22/200, Loss: 0.7320\n",
      "Epoch 23/200, Loss: 0.7320\n",
      "Epoch 24/200, Loss: 0.7320\n",
      "Epoch 25/200, Loss: 0.7320\n",
      "Epoch 26/200, Loss: 0.7320\n",
      "Epoch 27/200, Loss: 0.7320\n",
      "Epoch 28/200, Loss: 0.7320\n",
      "Epoch 29/200, Loss: 0.6414\n",
      "Epoch 30/200, Loss: 0.5346\n",
      "Epoch 31/200, Loss: 0.5355\n",
      "Epoch 32/200, Loss: 0.5478\n",
      "Epoch 33/200, Loss: 0.5269\n",
      "Epoch 34/200, Loss: 0.5227\n",
      "Epoch 35/200, Loss: 0.5206\n",
      "Epoch 36/200, Loss: 0.5199\n",
      "Epoch 37/200, Loss: 0.5261\n",
      "Epoch 38/200, Loss: 0.5204\n",
      "Epoch 39/200, Loss: 0.5228\n",
      "Epoch 40/200, Loss: 0.5185\n",
      "Epoch 41/200, Loss: 0.5190\n",
      "Epoch 42/200, Loss: 0.5189\n",
      "Epoch 43/200, Loss: 0.5151\n",
      "Epoch 44/200, Loss: 0.5182\n",
      "Epoch 45/200, Loss: 0.5165\n",
      "Epoch 46/200, Loss: 0.5136\n",
      "Epoch 47/200, Loss: 0.5141\n",
      "Epoch 48/200, Loss: 0.5151\n",
      "Epoch 49/200, Loss: 0.5139\n",
      "Epoch 50/200, Loss: 0.5151\n",
      "Epoch 51/200, Loss: 0.5146\n",
      "Epoch 52/200, Loss: 0.5130\n",
      "Epoch 53/200, Loss: 0.5120\n",
      "Epoch 54/200, Loss: 0.5113\n",
      "Epoch 55/200, Loss: 0.5149\n",
      "Epoch 56/200, Loss: 0.5150\n",
      "Epoch 57/200, Loss: 0.5107\n",
      "Epoch 58/200, Loss: 0.5187\n",
      "Epoch 59/200, Loss: 0.5109\n",
      "Epoch 60/200, Loss: 0.5130\n",
      "Epoch 61/200, Loss: 0.5123\n",
      "Epoch 62/200, Loss: 0.5114\n",
      "Epoch 63/200, Loss: 0.5108\n",
      "Epoch 64/200, Loss: 0.5092\n",
      "Epoch 65/200, Loss: 0.5108\n",
      "Epoch 66/200, Loss: 0.5102\n",
      "Epoch 67/200, Loss: 0.5094\n",
      "Epoch 68/200, Loss: 0.5131\n",
      "Epoch 69/200, Loss: 0.5113\n",
      "Epoch 70/200, Loss: 0.5092\n",
      "Epoch 71/200, Loss: 0.5148\n",
      "Epoch 72/200, Loss: 0.5122\n",
      "Epoch 73/200, Loss: 0.5092\n",
      "Epoch 74/200, Loss: 0.5093\n",
      "Epoch 75/200, Loss: 0.5086\n",
      "Epoch 76/200, Loss: 0.5096\n",
      "Epoch 77/200, Loss: 0.5087\n",
      "Epoch 78/200, Loss: 0.5097\n",
      "Epoch 79/200, Loss: 0.5074\n",
      "Epoch 80/200, Loss: 0.5107\n",
      "Epoch 81/200, Loss: 0.5083\n",
      "Epoch 82/200, Loss: 0.5089\n",
      "Epoch 83/200, Loss: 0.5079\n",
      "Epoch 84/200, Loss: 0.5067\n",
      "Epoch 85/200, Loss: 0.5113\n",
      "Epoch 86/200, Loss: 0.5090\n",
      "Epoch 87/200, Loss: 0.5090\n",
      "Epoch 88/200, Loss: 0.5072\n",
      "Epoch 89/200, Loss: 0.5086\n",
      "Epoch 90/200, Loss: 0.5204\n",
      "Epoch 91/200, Loss: 0.5132\n",
      "Epoch 92/200, Loss: 0.5094\n",
      "Epoch 93/200, Loss: 0.5069\n",
      "Epoch 94/200, Loss: 0.5074\n",
      "Epoch 95/200, Loss: 0.5115\n",
      "Epoch 96/200, Loss: 0.5082\n",
      "Epoch 97/200, Loss: 0.5112\n",
      "Epoch 98/200, Loss: 0.5058\n",
      "Epoch 99/200, Loss: 0.5075\n",
      "Epoch 100/200, Loss: 0.5065\n",
      "Epoch 101/200, Loss: 0.5111\n",
      "Epoch 102/200, Loss: 0.5078\n",
      "Epoch 103/200, Loss: 0.5065\n",
      "Epoch 104/200, Loss: 0.5076\n",
      "Epoch 105/200, Loss: 0.5078\n",
      "Epoch 106/200, Loss: 0.5068\n",
      "Epoch 107/200, Loss: 0.5099\n",
      "Epoch 108/200, Loss: 0.5086\n",
      "Epoch 109/200, Loss: 0.5058\n",
      "Epoch 110/200, Loss: 0.5050\n",
      "Epoch 111/200, Loss: 0.5098\n",
      "Epoch 112/200, Loss: 0.5071\n",
      "Epoch 113/200, Loss: 0.5054\n",
      "Epoch 114/200, Loss: 0.5074\n",
      "Epoch 115/200, Loss: 0.5075\n",
      "Epoch 116/200, Loss: 0.5065\n",
      "Epoch 117/200, Loss: 0.5036\n",
      "Epoch 118/200, Loss: 0.5079\n",
      "Epoch 119/200, Loss: 0.5035\n",
      "Epoch 120/200, Loss: 0.5062\n",
      "Epoch 121/200, Loss: 0.5047\n",
      "Epoch 122/200, Loss: 0.5071\n",
      "Epoch 123/200, Loss: 0.5062\n",
      "Epoch 124/200, Loss: 0.5057\n",
      "Epoch 125/200, Loss: 0.5024\n",
      "Epoch 126/200, Loss: 0.5030\n",
      "Epoch 127/200, Loss: 0.5043\n",
      "Epoch 128/200, Loss: 0.5060\n",
      "Epoch 129/200, Loss: 0.5033\n",
      "Epoch 130/200, Loss: 0.5033\n",
      "Epoch 131/200, Loss: 0.5045\n",
      "Epoch 132/200, Loss: 0.5078\n",
      "Epoch 133/200, Loss: 0.5024\n",
      "Epoch 134/200, Loss: 0.5015\n",
      "Epoch 135/200, Loss: 0.5064\n",
      "Epoch 136/200, Loss: 0.5075\n",
      "Epoch 137/200, Loss: 0.5016\n",
      "Epoch 138/200, Loss: 0.5023\n",
      "Epoch 139/200, Loss: 0.5007\n",
      "Epoch 140/200, Loss: 0.5005\n",
      "Epoch 141/200, Loss: 0.5006\n",
      "Epoch 142/200, Loss: 0.5006\n",
      "Epoch 143/200, Loss: 0.5023\n",
      "Epoch 144/200, Loss: 0.5003\n",
      "Epoch 145/200, Loss: 0.5033\n",
      "Epoch 146/200, Loss: 0.5018\n",
      "Epoch 147/200, Loss: 0.4992\n",
      "Epoch 148/200, Loss: 0.5007\n",
      "Epoch 149/200, Loss: 0.4995\n",
      "Epoch 150/200, Loss: 0.5018\n",
      "Epoch 151/200, Loss: 0.4983\n",
      "Epoch 152/200, Loss: 0.5035\n",
      "Epoch 153/200, Loss: 0.5041\n",
      "Epoch 154/200, Loss: 0.5004\n",
      "Epoch 155/200, Loss: 0.5003\n",
      "Epoch 156/200, Loss: 0.4977\n",
      "Epoch 157/200, Loss: 0.5010\n",
      "Epoch 158/200, Loss: 0.4998\n",
      "Epoch 159/200, Loss: 0.5025\n",
      "Epoch 160/200, Loss: 0.4989\n",
      "Epoch 161/200, Loss: 0.4995\n",
      "Epoch 162/200, Loss: 0.4971\n",
      "Epoch 163/200, Loss: 0.4994\n",
      "Epoch 164/200, Loss: 0.4971\n",
      "Epoch 165/200, Loss: 0.4991\n",
      "Epoch 166/200, Loss: 0.4953\n",
      "Epoch 167/200, Loss: 0.5012\n",
      "Epoch 168/200, Loss: 0.4985\n",
      "Epoch 169/200, Loss: 0.4962\n",
      "Epoch 170/200, Loss: 0.5054\n",
      "Epoch 171/200, Loss: 0.4981\n",
      "Epoch 172/200, Loss: 0.4989\n",
      "Epoch 173/200, Loss: 0.4995\n",
      "Epoch 174/200, Loss: 0.5007\n",
      "Epoch 175/200, Loss: 0.4989\n",
      "Epoch 176/200, Loss: 0.4963\n",
      "Epoch 177/200, Loss: 0.4988\n",
      "Epoch 178/200, Loss: 0.5021\n",
      "Epoch 179/200, Loss: 0.4981\n",
      "Epoch 180/200, Loss: 0.4977\n",
      "Epoch 181/200, Loss: 0.4965\n",
      "Epoch 182/200, Loss: 0.4979\n",
      "Epoch 183/200, Loss: 0.4998\n",
      "Epoch 184/200, Loss: 0.5035\n",
      "Epoch 185/200, Loss: 0.4989\n",
      "Epoch 186/200, Loss: 0.4997\n",
      "Epoch 187/200, Loss: 0.4964\n",
      "Epoch 188/200, Loss: 0.4998\n",
      "Epoch 189/200, Loss: 0.4962\n",
      "Epoch 190/200, Loss: 0.4965\n",
      "Epoch 191/200, Loss: 0.4996\n",
      "Epoch 192/200, Loss: 0.4976\n",
      "Epoch 193/200, Loss: 0.4963\n",
      "Epoch 194/200, Loss: 0.4957\n",
      "Epoch 195/200, Loss: 0.4952\n",
      "Epoch 196/200, Loss: 0.4950\n",
      "Epoch 197/200, Loss: 0.4941\n",
      "Epoch 198/200, Loss: 0.4960\n",
      "Epoch 199/200, Loss: 0.4953\n",
      "Epoch 200/200, Loss: 0.4951\n",
      "Results with pagerank normalization - Accuracy: 0.7475, Precision: 0.7504, Recall: 0.7475, F1 Score: 0.7422\n",
      "\n",
      "Training model with betweenness normalization...\n",
      "DataLoader batch size: 50\n",
      "Epoch 1/200, Loss: 0.8361\n",
      "Epoch 2/200, Loss: 0.8147\n",
      "Epoch 3/200, Loss: 0.7345\n",
      "Epoch 4/200, Loss: 0.7370\n",
      "Epoch 5/200, Loss: 0.7370\n",
      "Epoch 6/200, Loss: 0.7370\n",
      "Epoch 7/200, Loss: 0.7370\n",
      "Epoch 8/200, Loss: 0.7370\n",
      "Epoch 9/200, Loss: 0.7370\n",
      "Epoch 10/200, Loss: 0.7370\n",
      "Epoch 11/200, Loss: 0.7370\n",
      "Epoch 12/200, Loss: 0.7370\n",
      "Epoch 13/200, Loss: 0.7370\n",
      "Epoch 14/200, Loss: 0.7370\n",
      "Epoch 15/200, Loss: 0.7370\n",
      "Epoch 16/200, Loss: 0.7370\n",
      "Epoch 17/200, Loss: 0.7370\n",
      "Epoch 18/200, Loss: 0.7370\n",
      "Epoch 19/200, Loss: 0.7370\n",
      "Epoch 20/200, Loss: 0.7370\n",
      "Epoch 21/200, Loss: 0.7370\n",
      "Epoch 22/200, Loss: 0.7370\n",
      "Epoch 23/200, Loss: 0.7370\n",
      "Epoch 24/200, Loss: 0.7370\n",
      "Epoch 25/200, Loss: 0.7370\n",
      "Epoch 26/200, Loss: 0.7370\n",
      "Epoch 27/200, Loss: 0.7370\n",
      "Epoch 28/200, Loss: 0.7370\n",
      "Epoch 29/200, Loss: 0.7370\n",
      "Epoch 30/200, Loss: 0.7370\n",
      "Epoch 31/200, Loss: 0.7370\n",
      "Epoch 32/200, Loss: 0.7370\n",
      "Epoch 33/200, Loss: 0.7370\n",
      "Epoch 34/200, Loss: 0.7370\n",
      "Epoch 35/200, Loss: 0.7370\n",
      "Epoch 36/200, Loss: 0.7370\n",
      "Epoch 37/200, Loss: 0.7370\n",
      "Epoch 38/200, Loss: 0.7370\n",
      "Epoch 39/200, Loss: 0.7370\n",
      "Epoch 40/200, Loss: 0.7370\n",
      "Epoch 41/200, Loss: 0.7370\n",
      "Epoch 42/200, Loss: 0.7370\n",
      "Epoch 43/200, Loss: 0.7370\n",
      "Epoch 44/200, Loss: 0.7370\n",
      "Epoch 45/200, Loss: 0.7370\n",
      "Epoch 46/200, Loss: 0.7370\n",
      "Epoch 47/200, Loss: 0.7370\n",
      "Epoch 48/200, Loss: 0.7370\n",
      "Epoch 49/200, Loss: 0.7370\n",
      "Epoch 50/200, Loss: 0.7370\n",
      "Epoch 51/200, Loss: 0.7370\n",
      "Epoch 52/200, Loss: 0.7370\n",
      "Epoch 53/200, Loss: 0.7370\n",
      "Epoch 54/200, Loss: 0.7370\n",
      "Epoch 55/200, Loss: 0.7370\n",
      "Epoch 56/200, Loss: 0.7370\n",
      "Epoch 57/200, Loss: 0.7370\n",
      "Epoch 58/200, Loss: 0.7370\n",
      "Epoch 59/200, Loss: 0.7370\n",
      "Epoch 60/200, Loss: 0.7370\n",
      "Epoch 61/200, Loss: 0.7370\n",
      "Epoch 62/200, Loss: 0.7370\n",
      "Epoch 63/200, Loss: 0.7370\n",
      "Epoch 64/200, Loss: 0.7370\n",
      "Epoch 65/200, Loss: 0.7370\n",
      "Epoch 66/200, Loss: 0.7370\n",
      "Epoch 67/200, Loss: 0.7370\n",
      "Epoch 68/200, Loss: 0.7370\n",
      "Epoch 69/200, Loss: 0.7370\n",
      "Epoch 70/200, Loss: 0.7370\n",
      "Epoch 71/200, Loss: 0.7370\n",
      "Epoch 72/200, Loss: 0.7370\n",
      "Epoch 73/200, Loss: 0.7370\n",
      "Epoch 74/200, Loss: 0.7370\n",
      "Epoch 75/200, Loss: 0.7370\n",
      "Epoch 76/200, Loss: 0.7370\n",
      "Epoch 77/200, Loss: 0.7370\n",
      "Epoch 78/200, Loss: 0.7370\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m     apply_pca_and_visualize_all_sns(embeddings_list, titles, labels_list)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 48\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# print('Beofre calling trianing')\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# print('After calling training')\u001b[39;00m\n\u001b[0;32m     50\u001b[0m train_losses_list\u001b[38;5;241m.\u001b[39mappend(train_losses)\n",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, optimizer, criterion, epochs, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     23\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Track total loss for each epoch\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Move data to the specified device\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# print('Moving data to device in train_model')\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Clear gradients for the next train step\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 147\u001b[0m, in \u001b[0;36mMoleculeDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m#TODO: Process and return a single item from the dataset as tensors.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     G, atom_labels, classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx]\n\u001b[1;32m--> 147\u001b[0m     X, A \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matom_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalization_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, A, torch\u001b[38;5;241m.\u001b[39mtensor(classification, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m, in \u001b[0;36mgraph_to_tensors\u001b[1;34m(G, atom_labels, normalization_func)\u001b[0m\n\u001b[0;32m     87\u001b[0m     idx2 \u001b[38;5;241m=\u001b[39m atom_labels\u001b[38;5;241m.\u001b[39mindex(j)\n\u001b[0;32m     88\u001b[0m     A[idx1, idx2] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 89\u001b[0m     A[idx2, idx1] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalization_func:\n\u001b[0;32m     92\u001b[0m     A \u001b[38;5;241m=\u001b[39m normalization_func(G, A)  \u001b[38;5;66;03m# Apply normalization if provided\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function to train and evaluate Graph Convolutional Network (GCN) models\n",
    "    with different graph normalization techniques, visualize training metrics, and perform\n",
    "    embedding analysis through PCA.\n",
    "\n",
    "    Assumes the presence of a GCN model class, data loader preparation functions, and\n",
    "    various normalization technique functions defined outside this script.\n",
    "    \"\"\"\n",
    "    # Configuration parameters\n",
    "    num_samples_per_type = 1000  # Number of samples per class/type\n",
    "    num_epochs = 200  # Number of training epochs\n",
    "    # Dictionary mapping normalization technique names to their corresponding functions\n",
    "    normalization_techniques = {\n",
    "        'degree': compute_degree_matrix_normalization,\n",
    "        'pagerank': compute_pagerank_normalization,\n",
    "        'betweenness': compute_betweenness_normalization,\n",
    "        'clustering': compute_clustering_coefficient_normalization,\n",
    "    }\n",
    "\n",
    "    # Lists for storing evaluation metrics and model information\n",
    "    metric_values = [[] for _ in range(4)]  # Lists to store Accuracy, Precision, Recall, F1 Score\n",
    "    normalization_names = []  # Names of the normalization techniques\n",
    "    train_losses_list = []  # Training loss values for each normalization technique\n",
    "    models = []  # Trained models\n",
    "\n",
    "    # Set the computation device (GPU or CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Loop over each normalization technique to train and evaluate a model\n",
    "    for name, norm_func in normalization_techniques.items():\n",
    "        print(f\"\\nTraining model with {name} normalization...\")\n",
    "        # Prepare data loaders\n",
    "        train_loader, test_loader = prepare_data_loaders(num_samples_per_type, normalization_func=norm_func, batch_size=50)\n",
    "        print(f\"DataLoader batch size: {train_loader.batch_size}\")\n",
    "\n",
    "        # print('After initialisaing')\n",
    "\n",
    "        # Initialize the GCN model, optimizer, and loss criterion\n",
    "        # print('Beofore creating the model')\n",
    "        model = GCN(nfeat=3, nhid=16, nclass=2).to(device)\n",
    "        # print('After creating te model')\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train the model\n",
    "        # print('Beofre calling trianing')\n",
    "        train_losses = train_model(model, train_loader, optimizer, criterion, epochs=num_epochs, device=device)\n",
    "        # print('After calling training')\n",
    "        train_losses_list.append(train_losses)\n",
    "\n",
    "        # Store the trained model\n",
    "        models.append(model)\n",
    "\n",
    "        # Evaluate the model's performance\n",
    "        accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device=device)\n",
    "        # Store the evaluation metrics\n",
    "        metric_values[0].append(accuracy)\n",
    "        metric_values[1].append(precision)\n",
    "        metric_values[2].append(recall)\n",
    "        metric_values[3].append(f1)\n",
    "        normalization_names.append(name)\n",
    "\n",
    "        # Output the evaluation results\n",
    "        print(f\"Results with {name} normalization - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Visualization of training losses and evaluation metrics for each normalization technique\n",
    "    metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    plot_training_losses(train_losses_list, normalization_names)\n",
    "    plot_metric_bar_charts(normalization_names, metric_values, metric_names)\n",
    "\n",
    "    # Embedding extraction and PCA visualization\n",
    "    embeddings_list = []\n",
    "    labels_list = []  # Labels for each set of embeddings\n",
    "    titles = []  # Titles for the PCA plots\n",
    "\n",
    "    # Extract embeddings and labels for each model\n",
    "    for name, model in zip(normalization_names, models):\n",
    "        print(f\"\\nExtracting embeddings for model trained with {name} normalization...\")\n",
    "        embeddings, labels = extract_embeddings(model, test_loader, device=device)\n",
    "        embeddings_list.append(embeddings)\n",
    "        labels_list.append(labels)  # Append corresponding labels\n",
    "        titles.append(f\"Embedding Distributions with {name} normalization\")\n",
    "\n",
    "    # Apply PCA and visualize the embeddings\n",
    "    apply_pca_and_visualize_all_sns(embeddings_list, titles, labels_list)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xg8ZtRfK463d",
   "metadata": {
    "id": "Xg8ZtRfK463d"
   },
   "source": [
    "# 2) Implementation of GraphSAGE with Node Sampling (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cn37bADeLk0h",
   "metadata": {
    "id": "cn37bADeLk0h"
   },
   "source": [
    "## 2.1) Dataset\n",
    "\n",
    "In this question, we are going to train and test GraphSAGE on a **node classification** task using a toy Protein-Protein Interaction (PPI) dataset.\n",
    "\n",
    "The dataset contains 24 graphs. The average number of nodes per graph is 2372. Each node has 50 features and 121 labels.\n",
    "\n",
    "Since we will work on a node classification task, we will select only one of the graphs.\n",
    "\n",
    "Below, we load the dataset and split into train/validation/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pKOlr5XwLoaw",
   "metadata": {
    "id": "pKOlr5XwLoaw"
   },
   "outputs": [],
   "source": [
    "def load_ppi_data():\n",
    "    # Load the dataset\n",
    "    dataset = PPIDataset()\n",
    "\n",
    "    # Select one graph from the PPI dataset\n",
    "    g = dataset[0]\n",
    "\n",
    "    # Extract features, labels\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "\n",
    "    num_nodes = g.number_of_nodes()\n",
    "    num_train = int(0.6 * num_nodes)  # 60% for training\n",
    "    num_val = int(0.2 * num_nodes)    # 20% for validation\n",
    "\n",
    "    # Create a random permutation of node indices\n",
    "    indices = torch.randperm(num_nodes)\n",
    "\n",
    "    # Assign the first num_train nodes to the training set\n",
    "    # Assign the next num_val nodes to the validation set\n",
    "    # Assign the remaining nodes to the test set\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    train_mask[indices[:num_train]] = True\n",
    "    val_mask[indices[num_train:num_train+num_val]] = True\n",
    "    test_mask[indices[num_train+num_val:]] = True\n",
    "\n",
    "    adj = g.adjacency_matrix().to_dense()\n",
    "\n",
    "    return features, labels, adj, train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rdp7_8kzLpZJ",
   "metadata": {
    "id": "Rdp7_8kzLpZJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\Tao\\.dgl\\ppi.zip from https://data.dgl.ai/dataset/ppi.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tao\\.dgl\\ppi.zip:  55%|█████▍    | 3.88M/7.09M [00:00<00:00, 38.5MB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tao\\.dgl\\ppi.zip: 100%|██████████| 7.09M/7.09M [00:00<00:00, 34.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to C:\\Users\\Tao\\.dgl\\ppi_4b14ad03\n",
      "Number of train nodes: 1060\n",
      "Number of val nodes: 353\n",
      "Number of test nodes: 354\n",
      "Number of features: 50\n",
      "Number of classes: 121\n"
     ]
    }
   ],
   "source": [
    "features, labels, adj, train_mask, val_mask, test_mask = load_ppi_data()\n",
    "\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)\n",
    "adj = adj.to(device)\n",
    "\n",
    "num_feats = features.shape[1]\n",
    "num_classes = labels.shape[1]\n",
    "\n",
    "# Convert one-hot encoding to class indices format\n",
    "# e.g.,\n",
    "# one-hot encoding vector [0, 0, 1, 0, 0, ....] is converted to class index 2.\n",
    "# To use torch.nn.CrossEntropyLoss, we need to have this class indices format. \n",
    "# For more information, check https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "train_features = features[train_mask]\n",
    "val_features = features[val_mask]\n",
    "test_features = features[test_mask]\n",
    "\n",
    "train_labels = labels[train_mask]\n",
    "val_labels = labels[val_mask]\n",
    "test_labels = labels[test_mask]\n",
    "\n",
    "train_adj = adj[train_mask][:, train_mask]\n",
    "val_adj = adj[val_mask][:, val_mask]\n",
    "test_adj = adj[test_mask][:, test_mask]\n",
    "\n",
    "print(f\"Number of train nodes: {train_adj.shape[0]}\")\n",
    "print(f\"Number of val nodes: {val_adj.shape[0]}\")\n",
    "print(f\"Number of test nodes: {test_adj.shape[0]}\")\n",
    "print(f\"Number of features: {num_feats}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FCGjLT2KfEPF",
   "metadata": {
    "id": "FCGjLT2KfEPF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Degree: 11.96981143951416\n"
     ]
    }
   ],
   "source": [
    "def compute_average_degree(A):\n",
    "    degrees = A.sum(dim=1)  # Sum along rows to get degrees\n",
    "    average_degree = degrees.mean().item()  # Compute the mean degree\n",
    "\n",
    "    return average_degree\n",
    "\n",
    "average_degree = compute_average_degree(train_adj)\n",
    "print(\"Average Degree:\", average_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MiyIOQSXMgqB",
   "metadata": {
    "id": "MiyIOQSXMgqB"
   },
   "source": [
    "## 2.2) Node-wise Sampling (15 points)\n",
    "Node-wise sampling involves aggregating a subset of neighbors for each node in the graph, as opposed to considering all neighbors for aggregation (see the Figure 1). \n",
    "\n",
    "In the GraphSAGE, they sample a fixed number of neighbors in each layer. More specifically, they use $K=2$ number of layers and for the first layer and second layer, they sample $S_1=25$ and $S_2=10$ neighbors, respectively. \n",
    "\n",
    "**Here, for simplicity, we will sample $S=S_1=S_2=5$ neighbors for both layers**.\n",
    "\n",
    "<img src=\"figures/nodewise_sampling.jpg\" alt=\"Node-wise sampling\" width=\"200\" />\n",
    "\n",
    "(Figure 1: Node-wise sampling<sup>1</sup>)\n",
    "\n",
    "<sup>1</sup>_Hamilton, W., Ying, Z., & Leskovec, J. (2017). Inductive representation learning on large graphs. Advances in neural information processing systems, 30._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zdm91LJaOMp3",
   "metadata": {
    "id": "Zdm91LJaOMp3"
   },
   "source": [
    "Below, you need to implement the sampler function. It takes the adj. matrix A and number of neighbors to sample, returns a list of lists including indices to sampled neighbors for each node in A.\n",
    "\n",
    "You can use [torch.randperm](https://pytorch.org/docs/stable/generated/torch.randperm.html) or feel free to use any other function that does the same job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OA2mQO3GOliw",
   "metadata": {
    "id": "OA2mQO3GOliw"
   },
   "outputs": [],
   "source": [
    "def sampler(A, num_samples):\n",
    "    \"\"\"\n",
    "    Samples \"num_samples\" amount of neighbors for each node in adj. matrix A\n",
    "    You can use uniform random sampling. No need for any importance sampling strategy.\n",
    "\n",
    "    Params:\n",
    "        A (Tensor): Adj. matrix of shape (N x N)\n",
    "        num_samples (int): Number of neighbors to sample for each node\n",
    "        where N is the number of nodes.\n",
    "\n",
    "    Returns:\n",
    "        A list of lists including indices to sampled neighbors for each node in A.\n",
    "    \"\"\"\n",
    "\n",
    "    N = A.shape[0]  # Number of nodes\n",
    "    sampled_neighbors = []\n",
    "\n",
    "    ########## YOUR CODE HERE ##########\n",
    "    # For each node, populate the sampled_neighors list\n",
    "    # Here is a dummy example with num_samples = 3\n",
    "    # sampled_neighbors = [[3, 41, 2], [53, 234], ...]\n",
    "    # for the first node, the indices for sampled neighbors are 3, 41 and 2.\n",
    "    # the second node has only 2 neighbors (smaller than the num_samples), thus we sampled all its neighbors.\n",
    "\n",
    "    # 1. First, find all its neighbours \n",
    "    # 2. If the number of neighbours is less than or equal to num_samples, then we just add all neighbours and add it to sampled_neighbours\n",
    "    # 3. If the number of neighbours is greater than num_samples, then we randomly select num_samples and add it to sampled_neighbours\n",
    "\n",
    "    for i in range(N):\n",
    "        neighbors = torch.where(A[:, i] > 0)[0].tolist()\n",
    "        if len(neighbors) > num_samples:\n",
    "            sampled_neighbors.append(random.sample(neighbors, k=num_samples))\n",
    "        else:\n",
    "            sampled_neighbors.append(neighbors)\n",
    "        \n",
    "    ####################################\n",
    "\n",
    "    return sampled_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HjtPeehpQIVP",
   "metadata": {
    "id": "HjtPeehpQIVP"
   },
   "source": [
    "Let's see the sampled neighbors for the first 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YfGkkONoPFo3",
   "metadata": {
    "id": "YfGkkONoPFo3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: Sampled Neighbors [0]\n",
      "Node 1: Sampled Neighbors [4, 1]\n",
      "Node 2: Sampled Neighbors [2]\n",
      "Node 3: Sampled Neighbors [3]\n",
      "Node 4: Sampled Neighbors [4, 1]\n",
      "Node 5: Sampled Neighbors [1, 5]\n",
      "Node 6: Sampled Neighbors [4, 6]\n",
      "Node 7: Sampled Neighbors [7]\n",
      "Node 8: Sampled Neighbors [8]\n",
      "Node 9: Sampled Neighbors [9]\n"
     ]
    }
   ],
   "source": [
    "# set num_samples to 2 just for now\n",
    "num_samples = 2\n",
    "\n",
    "sampled_neighbors = sampler(adj[:10], num_samples)\n",
    "\n",
    "# Print the sampled neighbors for each node\n",
    "for node, neighbors in enumerate(sampled_neighbors):\n",
    "    print(f\"Node {node}: Sampled Neighbors {neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "It_a42RolM_h",
   "metadata": {
    "id": "It_a42RolM_h"
   },
   "source": [
    "## 2.3) Implementation of GraphSAGE (15 points)\n",
    "\n",
    "In Figure 2, you can find the pseudo-code for the forward propagation of GraphSAGE. Basically, in each layer, GraphSAGE iterates over all the nodes in the graph and aggregates the neighborhood information from a set of sampled neighbors. Then, different from the original GCN model<sup>2</sup>, the embedding of the current node is concatenated with the aggregated embedding, doubling the size of the embedding vector before applying linear transformation via the learnable parameter $W^k$. After that, the embedding of the current node is updated following the application of a non-linearity.\n",
    "\n",
    "They use different AGGREGATE functions such as mean and max-pooling aggregation. In this question, you need to use mean aggregation.\n",
    "\n",
    "We choose the number of layers as $K=2$ and non-linearity as $ReLU$.\n",
    "\n",
    "It is OK to skip the normalization in the line 7.\n",
    "\n",
    "<img src=\"figures/graphsage_algo.jpg\" alt=\"GraphSAGE Algorithm\" width=\"700\" />\n",
    "\n",
    "(Figure 2: Forward propagation of GraphSAGE<sup>3</sup>)\n",
    "\n",
    "<sup>2</sup>*Kipf, T. N., & Welling, M. (2016). Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907.*\n",
    "\n",
    "<sup>3</sup>*Liu, X., Yan, M., Deng, L., Li, G., Ye, X., & Fan, D. (2021). Sampling methods for efficient training of graph convolutional networks: A survey. IEEE/CAA Journal of Automatica Sinica, 9(2), 205-234.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kcyM2ioCR939",
   "metadata": {
    "id": "kcyM2ioCR939"
   },
   "outputs": [],
   "source": [
    "class GraphSAGEConvLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphSAGEConvLayer, self).__init__()\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # Define the learnable parameter W to be used in linear transformation\n",
    "        # Take into account the dimension increase resulting from the concatenation\n",
    "        # of the aggregated neighbor embeddings with the current node embedding.\n",
    "        #\n",
    "        # self.W = ...\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W = nn.Parameter(torch.randn(input_dim * 2, output_dim) * torch.sqrt(torch.tensor(2.0) / (input_dim * 2 + output_dim)))\n",
    "        self.beta = nn.Parameter(torch.zeros(output_dim))  \n",
    "        ####################################\n",
    "\n",
    "\n",
    "    def forward(self, curr_node_emb, neighbor_embs):\n",
    "        \"\"\"\n",
    "        Forward pass of a single GraphSAGE convolution layer\n",
    "\n",
    "        Params:\n",
    "        curr_node_emb (Tensor): Embedding vector of the current node.\n",
    "        neighbor_embs (Tensor): Embedding vectors of sampled neighbors of the current node\n",
    "\n",
    "        Returns:\n",
    "        Tensor: New embedding of the current node\n",
    "        \"\"\"\n",
    "\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # 1. Aggregate neighbor embeddings using mean aggregation\n",
    "        # 2. Concatenate the aggregated embeddings with the embedding of the current node\n",
    "        # 3. Apply linear transformation using self.W\n",
    "        # 4. Apply ReLU non-linearity\n",
    "        # 5. Return the new_embedding\n",
    "        agg_neighbors = torch.mean(neighbor_embs, dim=0)\n",
    "        emb = torch.cat((curr_node_emb, agg_neighbors))\n",
    "        emb = torch.matmul(emb, self.W)\n",
    "        return F.relu(emb)\n",
    "        ####################################\n",
    "\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_samples):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            GraphSAGEConvLayer(input_dim, hidden_dim),\n",
    "            GraphSAGEConvLayer(hidden_dim, num_classes)\n",
    "        ])\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        \"\"\"\n",
    "        Forward pass of GraphSAGE\n",
    "\n",
    "        Params:\n",
    "        X (Tensor): Node feature matrix of shape (N x d)\n",
    "        A (Tensor): Adj. matrix of shape (N x N)\n",
    "        where N is the number of nodes and d is the embedding size.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The output matrix of the last layer with shape (N x num_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        ########## YOUR CODE HERE ##########\n",
    "        # 1. For each layer:\n",
    "        #   1.1. Sample neighbors using the sampler function and adj matrix A\n",
    "        #   1.2. Update the embedding for each node\n",
    "        #     1.2.1 Forward pass through the GraphSAGE convolution layer\n",
    "        #     1.2.2 Store the new embeddings for each node\n",
    "        #   1.3. Update the node feature matrix for the next layer\n",
    "        # 2. Return the final node feature matrix with shape (N x num_classes)\n",
    "        N = X.shape[0]\n",
    "        curr_embs = X \n",
    "        for layer in self.layers:\n",
    "            sampled_neighbors = sampler(A, self.num_samples)\n",
    "            new_embs = torch.zeros(N, layer.output_dim)\n",
    "            for i in range(N):\n",
    "                curr_node_emb = curr_embs[i, :]\n",
    "                neighbor_embs = curr_embs[sampled_neighbors[i], :]\n",
    "                new_node_emb = layer(curr_node_emb, neighbor_embs)\n",
    "                new_embs[i, :] = new_node_emb\n",
    "            curr_embs = new_embs\n",
    "        return curr_embs\n",
    "        ####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upLxt7pwWgXn",
   "metadata": {
    "id": "upLxt7pwWgXn"
   },
   "outputs": [],
   "source": [
    "def trainStepGraphSAGE(model, features, adj, labels, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(features, adj)\n",
    "    train_loss = loss_fn(logits, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fjxyx9j6Wl8m",
   "metadata": {
    "id": "Fjxyx9j6Wl8m"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def testGraphSAGE(model, features, adj, labels):\n",
    "    model.eval()\n",
    "    logits = model(features, adj)\n",
    "\n",
    "    _, predicted = torch.max(logits, 1)\n",
    "\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "woYruDm-Wbrn",
   "metadata": {
    "id": "woYruDm-Wbrn"
   },
   "outputs": [],
   "source": [
    "def trainGraphSAGE(model, train_features, val_features, train_adj, val_adj, train_labels, val_labels, num_epochs=50):\n",
    "    t = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_acc = 0\n",
    "\n",
    "    for epoch in range(1, 1 + num_epochs):\n",
    "        train_loss = trainStepGraphSAGE(model, train_features, train_adj, train_labels, loss_fn, optimizer)\n",
    "        val_acc = testGraphSAGE(model, val_features, val_adj, val_labels)\n",
    "        if val_acc > best_valid_acc:\n",
    "            best_valid_acc = val_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        \n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "            f'Train Loss: {train_loss:.4f}, ',\n",
    "            f'Validation Accuracy: {100*val_acc:.4f}%, ',\n",
    "            f'time: {time.time() - t:.4f}s.')\n",
    "    \n",
    "    print(f'best acc_valid: {100*best_valid_acc:.4f}%')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gxNlHZg0XAEE",
   "metadata": {
    "id": "gxNlHZg0XAEE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGE(\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x GraphSAGEConvLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to play with hidden_dim :)\n",
    "hidden_dim = 64\n",
    "model = GraphSAGE(num_feats, hidden_dim, num_classes, num_samples=5)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nwJWPpEVaJo8",
   "metadata": {
    "id": "nwJWPpEVaJo8"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainGraphSAGE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 10\u001b[0m, in \u001b[0;36mtrainGraphSAGE\u001b[1;34m(model, train_features, val_features, train_adj, val_adj, train_labels, val_labels, num_epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m best_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m num_epochs):\n\u001b[1;32m---> 10\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainStepGraphSAGE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m testGraphSAGE(model, val_features, val_adj, val_labels)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_valid_acc:\n",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m, in \u001b[0;36mtrainStepGraphSAGE\u001b[1;34m(model, features, adj, labels, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 81\u001b[0m, in \u001b[0;36mGraphSAGE.forward\u001b[1;34m(self, X, A)\u001b[0m\n\u001b[0;32m     79\u001b[0m     curr_node_emb \u001b[38;5;241m=\u001b[39m curr_embs[i, :]\n\u001b[0;32m     80\u001b[0m     neighbor_embs \u001b[38;5;241m=\u001b[39m curr_embs[sampled_neighbors[i], :]\n\u001b[1;32m---> 81\u001b[0m     new_node_emb \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_node_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_embs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     new_embs[i, :] \u001b[38;5;241m=\u001b[39m new_node_emb\n\u001b[0;32m     83\u001b[0m curr_embs \u001b[38;5;241m=\u001b[39m new_embs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m, in \u001b[0;36mGraphSAGEConvLayer.forward\u001b[1;34m(self, curr_node_emb, neighbor_embs)\u001b[0m\n\u001b[0;32m     35\u001b[0m agg_neighbors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(neighbor_embs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((curr_node_emb, agg_neighbors))\n\u001b[1;32m---> 37\u001b[0m emb \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(emb)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "best_model = trainGraphSAGE(model, train_features, val_features, train_adj, val_adj, train_labels, val_labels, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97776f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.8814%\n"
     ]
    }
   ],
   "source": [
    "# You should get around 70-75% test accuracy.\n",
    "test_acc = testGraphSAGE(best_model, test_features, test_adj, test_labels)\n",
    "print(f\"Test Accuracy: {100*test_acc:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6t4V24ZpjXJx",
   "metadata": {
    "id": "6t4V24ZpjXJx"
   },
   "source": [
    "# 3) Attention-based aggregation in node classification (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dSBj13VcNy0",
   "metadata": {
    "id": "0dSBj13VcNy0"
   },
   "source": [
    "The objective is to develop two types of aggregation methods: mean aggregation and aggregation by attention.\n",
    "\n",
    "For those who require additional guidance or clarification, it is recommended to revisit the relevant [lecture](https://www.youtube.com/watch?v=zRmzVkidkqA&list=PLug43ldmRSo14Y_vt7S6vanPGh-JpHR7T&index=13) or consult the course [notes](https://drive.google.com/file/d/1p7U1xyW4-5W4ge8gRstUkBGQSY3fKHX6/view).\n",
    "\n",
    "\n",
    "Important Reminder: Please ensure that you execute all the cells in each section in sequence to maintain the integrity of intermediate variables and package imports.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g_df0zRghF1b",
   "metadata": {
    "id": "g_df0zRghF1b"
   },
   "source": [
    "## Constructing Layers for Graph Neural Networks (17 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neppPZh5g_47",
   "metadata": {
    "id": "neppPZh5g_47"
   },
   "source": [
    "Let's begin by creating a dummy dataset that will aid in the development and testing of our Graph Neural Networks (GNNs). This dataset will include a simple graph structure with defined nodes, edges, and node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jju0azWFhevg",
   "metadata": {
    "id": "jju0azWFhevg"
   },
   "outputs": [],
   "source": [
    "def create_dummy_data(n_nodes, n_features):\n",
    "  # Create a random adjacency matrix for an undirected graph\n",
    "  # Use a random integer matrix and make it symmetric\n",
    "  adj = torch.triu(torch.randint(0, 2, (n_nodes, n_nodes)), diagonal=1)\n",
    "  adj = adj + adj.T\n",
    "\n",
    "  # Create random features for each node\n",
    "  adj = adj.type(torch.float)\n",
    "  x = torch.rand(n_nodes, n_features)\n",
    "\n",
    "  return x, adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7qDSC9VthjlE",
   "metadata": {
    "id": "7qDSC9VthjlE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "x, adj = create_dummy_data(5, 3)\n",
    "print(x.shape)\n",
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "djXNL49_hqyt",
   "metadata": {
    "id": "djXNL49_hqyt"
   },
   "source": [
    "### Building a Graph Neural Network with Mean Aggregation (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_NRLPPhhs_v",
   "metadata": {
    "id": "e_NRLPPhhs_v"
   },
   "source": [
    "Observe that the GNN utilizing a mean aggregator is significantly influenced by how the adjacency matrix is normalized.\n",
    "\n",
    "The formula for the next layer's node representations is given by:\n",
    "\n",
    "$H_{k+1} = a[\\beta_k\\mathbf{1}^T + \\Omega_kH_k(AD^{-1}+I)]$\n",
    "\n",
    "We will proceed to implement the mean normalization of the adjacency matrix using the following expression:\n",
    "\n",
    "$\\widetilde{A}=AD^{-1}+I$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DqOma83HjBth",
   "metadata": {
    "id": "DqOma83HjBth"
   },
   "outputs": [],
   "source": [
    "def mean_normalization(A):\n",
    "  ############# Your code here ############\n",
    "  ## Note:\n",
    "  ## 1. Calculate the degree matrix\n",
    "  ## 2. Create the inverse of the degree matrix\n",
    "  ## 3. Compute the mean normalization of the adjacency matrix\n",
    "  ## (~3 lines of code)\n",
    "  epsilon = 1e-5 # Small constant to avoid division by zero \n",
    "  I = torch.eye(A.size(0))\n",
    "  D_inv = torch.diag(1.0 / epsilon + torch.sum(A, dim=0))\n",
    "  A = A.matmul(D_inv) + I\n",
    "  #########################################\n",
    "  return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wSLQfIfjjChw",
   "metadata": {
    "id": "wSLQfIfjjChw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+05, 0.0000e+00, 0.0000e+00, 1.0000e+05],\n",
       "        [1.0000e+05, 1.0000e+00, 0.0000e+00, 1.0000e+05, 1.0000e+05],\n",
       "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+05, 1.0000e+05],\n",
       "        [0.0000e+00, 1.0000e+05, 1.0000e+05, 1.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+05, 1.0000e+05, 1.0000e+05, 0.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test your implementation to observe the behavior of the\n",
    "## mean normalization adjacency matrix.\n",
    "## Note:\n",
    "## It should reflect the values normalized over the number of neighbors,\n",
    "## with the inclusion of a self-loop for each node\n",
    "mean_normalization(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gpq54RcAlyHm",
   "metadata": {
    "id": "gpq54RcAlyHm"
   },
   "source": [
    "Now, let's build the GCN layer with a mean aggregator. Remeber, node features are computed as follows:\n",
    "\n",
    "$H_{k+1} = a[\\beta_k\\mathbf{1}^T + \\Omega_kH_k(AD^{-1}+I)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D2gWjKtDmCUW",
   "metadata": {
    "id": "D2gWjKtDmCUW"
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic implementation of GCN layer.\n",
    "    It aggregates information from a node's neighbors\n",
    "    using mean aggregation.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        super(GCN, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        # self.bias = nn.Parameter(torch.zeros(out_features)) no bias??\n",
    "        self.activation = activation\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        Forward pass of the GCN layer.\n",
    "\n",
    "        Parameters:\n",
    "        input (Tensor): The input features of the nodes.\n",
    "        adj (Tensor): The adjacency matrix of the graph.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The output features of the nodes after applying the GCN layer.\n",
    "        \"\"\"\n",
    "        adj_norm = mean_normalization(adj)\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Apply the linear transformation\n",
    "        ## 2. Perform the graph convolution operation\n",
    "        ## Note: rename the last line as `output`\n",
    "        ## (2 lines of code)\n",
    "        agg = torch.matmul(adj_norm, x)\n",
    "        # output = torch.matmul(agg, self.weight) + self.bias\n",
    "        output = torch.matmul(agg, self.weight)\n",
    "        #########################################\n",
    "        h = self.activation(output) if self.activation else output\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YzuoVNnenV93",
   "metadata": {
    "id": "YzuoVNnenV93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-112900.8203,   46216.1914,  -41579.5352],\n",
       "        [-111038.2578,   17542.9141,  -30191.8574],\n",
       "        [ -74855.7344,    9079.6816,  -18159.5996],\n",
       "        [-137090.8594,   53380.9414,  -50403.3125],\n",
       "        [-173273.1406,   61843.8516,  -62435.3984]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensure that your implementation is flexible enough to accommodate changes\n",
    "## in the number of hidden features. Verify that the dimensions of all\n",
    "## matrices are correctly aligned, allowing for a successful forward\n",
    "## pass through the network.\n",
    "GCN(x.size(1), 3)(x, adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0g-hfZN1pHCo",
   "metadata": {
    "id": "0g-hfZN1pHCo"
   },
   "source": [
    "### Developing a Graph Neural Network with Attention-Based Aggregation (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uEVWsPIYruLD",
   "metadata": {
    "id": "uEVWsPIYruLD"
   },
   "source": [
    "The transformed node embeddings $H_k^{'}$ are calculated using the formula:\n",
    "\n",
    "\\begin{equation}\n",
    "H_k^{'} = \\beta_k\\mathbf{1}^T + \\Omega_kH_k\n",
    "\\end{equation}\n",
    "\n",
    "In this equation, $\\beta_k$ and $\\Omega_k$ are parameters, and $H_k$ represents the node embeddings at layer $k$.\n",
    "\n",
    "To compute the similarity $s_{mn}$ between any two transformed node embeddings $h^{'}_m$ and $h^{'}_n$, we concatenate these embeddings and then take a dot product with a learned parameter vector $\\phi_k$. An activation function is then applied to this dot product:\n",
    "\n",
    "\\begin{equation}\n",
    "s_{mn} = a\\left[\\phi_k^T \\begin{bmatrix} h^{'}_m\\\\ h^{'}_n \\end{bmatrix}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "These similarity values are organized into an $N \\times N$ matrix $S$, where each element represents the similarity between every pair of nodes.\n",
    "\n",
    "The attention weights that contribute to each output embedding are normalized to ensure they are positive and sum to one.\n",
    "\n",
    "This normalization is achieved using the softmax operation. However, it's important to note that only the values corresponding to a node and its neighbors are considered in this computation. The attention weights are then applied to the transformed embeddings as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "a[H_k^{'} * \\text{Softmax}(S, A+I)]\n",
    "\\end{equation}\n",
    "\n",
    "Here, $A+I$ represents the adjacency matrix with added self-loops, ensuring that each node also considers itself when computing attention weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4nXvTZUvvN62",
   "metadata": {
    "id": "4nXvTZUvvN62"
   },
   "source": [
    "To get started, it's important to grasp how to calculate the similarity matrix.\n",
    "\n",
    "A straightforward approach would be to iterate through all the nodes and compute the similarity scores for each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wfJx30JZpGXp",
   "metadata": {
    "id": "wfJx30JZpGXp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8622, 1.4380, 0.9755, 0.8977, 0.9153],\n",
      "        [1.5133, 2.0891, 1.6267, 1.5489, 1.5664],\n",
      "        [1.5286, 2.1044, 1.6419, 1.5641, 1.5817],\n",
      "        [1.3828, 1.9586, 1.4961, 1.4183, 1.4358],\n",
      "        [1.3777, 1.9535, 1.4911, 1.4132, 1.4308]])\n"
     ]
    }
   ],
   "source": [
    "N = x.size(0)\n",
    "D = 3\n",
    "\n",
    "# Initialize H' and phi with random values\n",
    "H = torch.rand(size=(N, D))\n",
    "phi = torch.rand(size=(2 * D,))\n",
    "\n",
    "# Initialize the similarity matrix S\n",
    "S = torch.zeros((N, N))\n",
    "\n",
    "# Loop over all nodes to compute the similarity scores\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        ############# Your code here ############\n",
    "        ## 1. Concatenate the features of nodes i and j\n",
    "        ## 2. Compute the dot product of concatenated features with phi\n",
    "        ## (2 lines of code)\n",
    "        h = torch.cat((H[i, :], H[j, :]))\n",
    "        S[i, j] = F.relu(torch.dot(phi, h))\n",
    "        #########################################\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Td_GQQX4wiUl",
   "metadata": {
    "id": "Td_GQQX4wiUl"
   },
   "source": [
    "It's crucial to apply a mask to the pre-attention scores before they are processed through the softmax function. This ensures that the normalization is applied exclusively to the existing edges in the graph, maintaining the integrity of the graph structure.\n",
    "\n",
    "\n",
    "Construct the mask using the following equation:\n",
    "$mask = A+I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_Tr83bLQwz6L",
   "metadata": {
    "id": "_Tr83bLQwz6L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True, False, False,  True],\n",
      "        [ True,  True, False,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "############# Your code here ############\n",
    "## contruct the mask, name it `mask`\n",
    "## return a boolean matrix NxN\n",
    "## (1 line of code)\n",
    "mask = (adj.clone().detach() + torch.eye(adj.size(0))).bool()\n",
    "#########################################\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4PCNdExKxVb2",
   "metadata": {
    "id": "4PCNdExKxVb2"
   },
   "source": [
    "Apply the mask to the pre-attention\n",
    "$S[mask]$.\n",
    "\n",
    "Set $S$ to very large negative values. This is effectively to represent negative infinity in the context of the softmax operation that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gzfru1H4w3jX",
   "metadata": {
    "id": "Gzfru1H4w3jX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3683, 4.2123, 2.4974, 4.5418, 8.0780, 4.7061, 4.7894, 5.1652, 4.7785,\n",
      "        4.8630, 7.0893, 4.4643, 4.1301, 3.9658, 7.0536, 4.4418, 4.1820])\n"
     ]
    }
   ],
   "source": [
    "############# Your code here ############\n",
    "## get masked values for S, `S_masked`\n",
    "## hint: see torch.where\n",
    "## Note: The values masked should effectively be zero,\n",
    "## considering the limits of numerical precision.\n",
    "## (1 line of code)\n",
    "S_masked = S[mask]\n",
    "#########################################\n",
    "print(S_masked.exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcNf5fYB1E21",
   "metadata": {
    "id": "fcNf5fYB1E21"
   },
   "source": [
    "\n",
    "Now, let's proceed to implement the Graph Attention Network (GAT). The preparatory work we've done should have provided you with all the necessary tools and understanding to successfully implement the attention based aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hMECcwy7pV6B",
   "metadata": {
    "id": "hMECcwy7pV6B"
   },
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic implementation of the GAT layer.\n",
    "\n",
    "    This layer applies an attention mechanism in the graph convolution process,\n",
    "    allowing the model to focus on different parts of the neighborhood\n",
    "    of each node.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, activation=None):\n",
    "        super(GAT, self).__init__()\n",
    "        # Initialize the weights, bias, and attention parameters as\n",
    "        # trainable parameters\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        self.phi = nn.Parameter(torch.FloatTensor(2 * out_features, 1))\n",
    "        self.activation = activation\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / np.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        stdv = 1. / np.sqrt(self.phi.size(1))\n",
    "        self.phi.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        \"\"\"\n",
    "        Forward pass of the GAT layer.\n",
    "\n",
    "        Parameters:\n",
    "        input (Tensor): The input features of the nodes.\n",
    "        adj (Tensor): The adjacency matrix of the graph.\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The output features of the nodes after applying the GAT layer.\n",
    "        \"\"\"\n",
    "        ############# Your code here ############\n",
    "        ## 1. Apply linear transformation and add bias\n",
    "        ## 2. Compute the attention scores utilizing the previously\n",
    "        ## established mechanism.\n",
    "        ## Note: Keep in mind that employing matrix notation can\n",
    "        ## optimize this process.\n",
    "        ## 3. Compute mask based on adjacency matrix\n",
    "        ## 4. Apply mask to the pre-attention matrix\n",
    "        ## 5. Compute attention weights using softmax\n",
    "        ## 6. Aggregate features based on attention weights\n",
    "        ## Note: name the last line as `h`\n",
    "        ## (9-10 lines of code)\n",
    "        N = input.size(0)\n",
    "        h = torch.matmul(input, self.weight) + self.bias\n",
    "        S = torch.zeros((N, N))\n",
    "\n",
    "        # Loop over all nodes to compute the similarity scores\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                h_concat = torch.cat((h[i, :], h[j, :]))\n",
    "                S[i, j] = torch.dot(phi, h_concat)\n",
    "                \n",
    "        mask = (adj.clone().detach() + torch.eye(adj.size(0))).bool()\n",
    "        att_weights = F.softmax(S * mask, dim=1)\n",
    "        print(att_weights)\n",
    "        h = torch.matmul(att_weights, h)\n",
    "        #########################################\n",
    "        return self.activation(h) if self.activation else h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OXVpydRKpV3m",
   "metadata": {
    "id": "OXVpydRKpV3m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1920, 0.2471, 0.1897, 0.1897, 0.1814],\n",
      "        [0.1917, 0.2468, 0.1790, 0.2013, 0.1811],\n",
      "        [0.2006, 0.2006, 0.1976, 0.2006, 0.2006],\n",
      "        [0.1849, 0.2451, 0.1849, 0.2000, 0.1849],\n",
      "        [0.1863, 0.2397, 0.1990, 0.1990, 0.1760]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2029, -0.3162, -0.0665],\n",
       "        [ 0.2031, -0.3169, -0.0652],\n",
       "        [ 0.2006, -0.3090, -0.0882],\n",
       "        [ 0.2025, -0.3163, -0.0661],\n",
       "        [ 0.2011, -0.3131, -0.0668]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ensure that your implementation is flexible enough to accommodate changes\n",
    "## in the number of hidden features. Verify that the dimensions of all\n",
    "## matrices are correctly aligned, allowing for a successful forward\n",
    "## pass through the network.\n",
    "GAT(x.size(1), 3).to(device)(x, adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rtH8rckF2hLR",
   "metadata": {
    "id": "rtH8rckF2hLR"
   },
   "source": [
    "## Node Classification (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B3IdKBlv2ulI",
   "metadata": {
    "id": "B3IdKBlv2ulI"
   },
   "source": [
    "Here is a GNN for node classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wSemM4ZJ2tkB",
   "metadata": {
    "id": "wSemM4ZJ2tkB"
   },
   "outputs": [],
   "source": [
    "class NodeClassifier(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, gnn_layer):\n",
    "        super(NodeClassifier, self).__init__()\n",
    "\n",
    "        self.gc1 = gnn_layer(nfeat, nhid, F.relu)\n",
    "        self.gc2 = gnn_layer(nhid, nclass, None)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IPhzOUiNazmc",
   "metadata": {
    "id": "IPhzOUiNazmc"
   },
   "source": [
    "Let's get hands-on experience by loading a benchmark dataset - the Cora dataset.\n",
    "\n",
    "Dataset: Cora is a widely-used benchmark in graph ML. It consists of a citation network where nodes represent scientific papers, and edges correspond to citations between these papers. Each paper (node) is described by a textual abstract and is categorized into one of several classes based on its content.\n",
    "\n",
    "Node Classification: we'll dive into  node classification where the goal is to predict the category of each paper in the Cora citation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E7x9tcgEZe3A",
   "metadata": {
    "id": "E7x9tcgEZe3A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "def load_cora_data(subset_size=100):\n",
    "    # Load the dataset\n",
    "    dataset = CoraGraphDataset()\n",
    "    g = dataset[0]\n",
    "    if subset_size > 0:\n",
    "      # Ensure subset_size is smaller than the total number of nodes\n",
    "      total_nodes = g.num_nodes()\n",
    "      subset_size = min(subset_size, total_nodes)\n",
    "\n",
    "      # Select a subset of nodes\n",
    "      subset_nodes = torch.randperm(total_nodes)[:subset_size]\n",
    "\n",
    "      # Create a subgraph with the selected nodes\n",
    "      subg = g.subgraph(subset_nodes)\n",
    "    else:\n",
    "      subg = g\n",
    "\n",
    "    # Extract features, labels, and masks for the graph\n",
    "    features = subg.ndata['feat']\n",
    "    labels = subg.ndata['label']\n",
    "    train_mask = subg.ndata['train_mask']\n",
    "    val_mask = subg.ndata['val_mask']\n",
    "    test_mask = subg.ndata['test_mask']\n",
    "\n",
    "    adj = subg.adjacency_matrix().to_dense()\n",
    "\n",
    "    return features, labels, adj, train_mask, val_mask, test_mask\n",
    "features, labels, adj, train_mask, val_mask, test_mask = load_cora_data(-1)\n",
    "\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)\n",
    "adj = adj.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "val_mask = val_mask.to(device)\n",
    "test_mask = test_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "za5azmEYvHMZ",
   "metadata": {
    "id": "za5azmEYvHMZ"
   },
   "source": [
    "Feel free to analyze and print the dimensions of *features, adj*, and *labels*. This will help you debug in case of errors.\n",
    "\n",
    "Note: you can take a subset of the full graph `load_cora_data(subset_size=1000)` to spead up development. However, we expect the final submission on the full graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3g_YeKQUTA0y",
   "metadata": {
    "id": "3g_YeKQUTA0y"
   },
   "source": [
    "Let's define metrics to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wvR11ZbbTEu4",
   "metadata": {
    "id": "wvR11ZbbTEu4"
   },
   "outputs": [],
   "source": [
    "def calculate_specificity(y_true, y_pred, labels):\n",
    "    specificity_scores = np.zeros(len(labels))\n",
    "    for i, label in enumerate(labels):\n",
    "        binary_true = (y_true == label).int()\n",
    "        binary_pred = (y_pred == label).int()\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(binary_true, binary_pred).ravel()\n",
    "\n",
    "        specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "        specificity_scores[i] = specificity\n",
    "\n",
    "    return np.mean(specificity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piwFKneJ4BNi",
   "metadata": {
    "id": "piwFKneJ4BNi"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(target, prediction):\n",
    "  ############# Your code here ############\n",
    "  ## 1. Count the number of correct predictions\n",
    "  ## 2. Get the total number of predictions\n",
    "  ## 3. Calculate the accuracy\n",
    "  ## (~3 lines of code)\n",
    "  correct_predictions = torch.sum(target == prediction)\n",
    "  total_predictions = len(target)\n",
    "  accuracy = correct_predictions / total_predictions\n",
    "  #########################################\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AFZVCe7DUNBV",
   "metadata": {
    "id": "AFZVCe7DUNBV"
   },
   "outputs": [],
   "source": [
    "sensitivity = lambda y_true, y_pred: recall_score(y_true.cpu(), y_pred.cpu(), average='macro')\n",
    "specificity = lambda y_true, y_pred: calculate_specificity(y_true.cpu(), y_pred.cpu(), labels.unique().cpu())\n",
    "accuracy = lambda y_true, y_pred: compute_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHzjkKv4vwA2",
   "metadata": {
    "id": "HHzjkKv4vwA2"
   },
   "source": [
    "Almost there, write the main training function to train our GNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BDvI2ZD4gQOj",
   "metadata": {
    "id": "BDvI2ZD4gQOj"
   },
   "outputs": [],
   "source": [
    "def train_step(model, X, A, y ,train_mask, optimizer, loss_fn):\n",
    "  model.train()\n",
    "  loss = 0\n",
    "  ############# Your code here ############\n",
    "  ## 1. Zero grad the optimizer\n",
    "  ## 2. Feed the data into the model\n",
    "  ## 3. Slice the model output and label by train_mask\n",
    "  ## 4. Feed the sliced output and label to loss_fn\n",
    "  ## (~4 lines of code)\n",
    "  # Step 1: Zero gradients\n",
    "  optimizer.zero_grad()\n",
    "  output = model(X, A)\n",
    "  output_train = output[train_mask]\n",
    "  y_train = y[train_mask]\n",
    "  loss = loss_fn(output_train, y_train)\n",
    "  #########################################\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zDBF9eMe31sg",
   "metadata": {
    "id": "zDBF9eMe31sg"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, X, A, y, train_mask, val_mask, test_mask=None, metrics={}):\n",
    "  model.eval()\n",
    "\n",
    "  # The output of model on all data\n",
    "  out = None\n",
    "  logits = model(X, A)\n",
    "  preds = logits.argmax(dim=1)\n",
    "\n",
    "  result = {\n",
    "        'train': {},\n",
    "        'val': {},\n",
    "      }\n",
    "  if test_mask is not None:\n",
    "    result['test'] = {}\n",
    "\n",
    "  for name, metric in metrics.items():\n",
    "    result['train'][name] = metric(y[train_mask], preds[train_mask])\n",
    "    result['val'][name] = metric(y[val_mask], preds[val_mask])\n",
    "\n",
    "    if test_mask is not None:\n",
    "      result['test'][name] = metric(y[test_mask], preds[test_mask])\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RJNEQbtB4xQY",
   "metadata": {
    "id": "RJNEQbtB4xQY"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, lr):\n",
    "  t = time.time()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                            lr=lr,\n",
    "                            weight_decay=5e-4)\n",
    "  loss_fn = F.nll_loss\n",
    "  metrics = {\"acc\": accuracy}\n",
    "\n",
    "  best_model = None\n",
    "  best_valid_acc = 0\n",
    "\n",
    "  for epoch in range(1, 1 + epochs):\n",
    "    loss = train_step(model, features, adj, labels, train_mask,\n",
    "                      optimizer, loss_fn)\n",
    "\n",
    "\n",
    "    result = test(model, features, adj, labels,\n",
    "                train_mask, val_mask, None, metrics)\n",
    "    train_acc = result['train']['acc']\n",
    "    valid_acc = result['val']['acc']\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, ',\n",
    "          f'acc_train: {100*train_acc:.4f}%, ',\n",
    "          f'acc_valid: {100*valid_acc:.4f}%, ',\n",
    "          f'time: {time.time() - t:.4f}s.')\n",
    "  print(f'best acc_valid: {100*best_valid_acc:.4f}%')\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7pGPt9EB9kD9",
   "metadata": {
    "id": "7pGPt9EB9kD9"
   },
   "source": [
    "Execute node classification on the Cora dataset using mean aggregation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcgU70zI8KXD",
   "metadata": {
    "id": "bcgU70zI8KXD"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Note:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m## feel free to play with the parameters to improve validation accuracy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m## you should get a validationaccuracy of at least 77%-80%\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_GCN \u001b[38;5;241m=\u001b[39m NodeClassifier(nfeat\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      5\u001b[0m                   nhid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m      6\u001b[0m                   nclass\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m                   dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m      8\u001b[0m                   gnn_layer\u001b[38;5;241m=\u001b[39mGCN)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 9\u001b[0m model_GCN \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_GCN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[182], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, epochs, lr)\u001b[0m\n\u001b[0;32m     10\u001b[0m best_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m epochs):\n\u001b[1;32m---> 13\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m   result \u001b[38;5;241m=\u001b[39m test(model, features, adj, labels,\n\u001b[0;32m     18\u001b[0m               train_mask, val_mask, \u001b[38;5;28;01mNone\u001b[39;00m, metrics)\n\u001b[0;32m     19\u001b[0m   train_acc \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[180], line 13\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, X, A, y, train_mask, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X, A)\n\u001b[0;32m     12\u001b[0m train \u001b[38;5;241m=\u001b[39m output[train_mask]\n\u001b[1;32m---> 13\u001b[0m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#########################################\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:2729\u001b[0m, in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2728\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "## Note:\n",
    "## feel free to play with the parameters to improve validation accuracy\n",
    "## you should get a validationaccuracy of at least 77%-80%\n",
    "model_GCN = NodeClassifier(nfeat=features.shape[1],\n",
    "                  nhid=16,\n",
    "                  nclass=labels.max().item() + 1,\n",
    "                  dropout=0.5,\n",
    "                  gnn_layer=GCN).to(device)\n",
    "model_GCN = train(model_GCN, 100, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8M_Shomo95Xq",
   "metadata": {
    "id": "8M_Shomo95Xq"
   },
   "source": [
    "Execute node classification on the Cora dataset using attention based aggregation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SaZjU5tn4yGk",
   "metadata": {
    "id": "SaZjU5tn4yGk"
   },
   "outputs": [],
   "source": [
    "## Note:\n",
    "## feel free to play with the parameters to improve validation accuracy\n",
    "## you should get a validationaccuracy of at least 77%-80%\n",
    "model_GAT = NodeClassifier(nfeat=features.shape[1],\n",
    "              nhid=16,\n",
    "              nclass=labels.max().item() + 1,\n",
    "              dropout=0.5,\n",
    "              gnn_layer=GAT).to(device)\n",
    "model_GAT = train(model_GAT, 100, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jAqFqoZPUTHN",
   "metadata": {
    "id": "jAqFqoZPUTHN"
   },
   "source": [
    "## Visualize and analize results (7 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-mAEk0w8ZiMy",
   "metadata": {
    "id": "-mAEk0w8ZiMy"
   },
   "source": [
    "\n",
    "Familiarize yourself with the following utility functions, which are designed for visual analysis and will assist us in evaluating our GNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_4lCscL3U1GG",
   "metadata": {
    "id": "_4lCscL3U1GG"
   },
   "outputs": [],
   "source": [
    "def plot_embeddings(embeddings1, embeddings2, labels):\n",
    "    # Convert multi-labels to unique integers for color-coding\n",
    "    unique_labels, label_indices = np.unique(labels, axis=0, return_inverse=True)\n",
    "\n",
    "    # Set up the matplotlib figure and axes\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Perform PCA for both sets of embeddings\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result1 = pca.fit_transform(embeddings1)\n",
    "    pca_result2 = pca.fit_transform(embeddings2)\n",
    "\n",
    "    # Plotting GCN\n",
    "    scatter1 = axs[0].scatter(pca_result1[:, 0], pca_result1[:, 1], c=label_indices, cmap='viridis')\n",
    "    axs[0].set_title('GCN')\n",
    "    axs[0].set_xlabel('PCA Component 1')\n",
    "    axs[0].set_ylabel('PCA Component 2')\n",
    "\n",
    "    # Plotting GAT\n",
    "    scatter2 = axs[1].scatter(pca_result2[:, 0], pca_result2[:, 1], c=label_indices, cmap='viridis')\n",
    "    axs[1].set_title('GAT')\n",
    "    axs[1].set_xlabel('PCA Component 1')\n",
    "    axs[1].set_ylabel('PCA Component 2')\n",
    "\n",
    "    # Create a color bar with label information\n",
    "    cbar = plt.colorbar(scatter1, ax=axs, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Label Combinations')\n",
    "    cbar.set_ticks(np.arange(len(unique_labels)))\n",
    "    cbar.set_ticklabels([' + '.join(str(comb)) for comb in unique_labels])\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4XlA1WI7YsnC",
   "metadata": {
    "id": "4XlA1WI7YsnC"
   },
   "outputs": [],
   "source": [
    "def plot_weight_distributions(weights1, weights2):\n",
    "    # Flatten the weight matrices\n",
    "    flattened_weights1 = weights1.flatten()\n",
    "    flattened_weights2 = weights2.flatten()\n",
    "\n",
    "    # Create KDE plots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.kdeplot(flattened_weights1, fill=True, color=\"r\", label=\"GCN\")\n",
    "    sns.kdeplot(flattened_weights2, fill=True, color=\"b\", label=\"GAT\")\n",
    "\n",
    "    plt.title(\"Distribution of GNN Weights\")\n",
    "    plt.xlabel(\"Weight Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uC6QMjPadcfk",
   "metadata": {
    "id": "uC6QMjPadcfk"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, title, phases = ['train', 'val', 'test']):\n",
    "    n_phases = len(phases)\n",
    "\n",
    "    # Setting up the subplot grid\n",
    "    fig, axs = plt.subplots(n_phases, 1, figsize=(15, 6 * n_phases), sharey=True)\n",
    "\n",
    "    for i, phase in enumerate(phases):\n",
    "        # Extracting metric names\n",
    "        metric_names = list(metrics[0][phase].keys())\n",
    "\n",
    "        # Number of metrics\n",
    "        n_metrics = len(metric_names)\n",
    "\n",
    "        # Data for plotting\n",
    "        scores_modelA = [metrics[0][phase][metric] for metric in metric_names]\n",
    "        scores_modelB = [metrics[1][phase][metric] for metric in metric_names]\n",
    "\n",
    "        # Setting the positions and width for the bars\n",
    "        pos = np.arange(n_metrics)\n",
    "        bar_width = 0.35\n",
    "\n",
    "        # Plotting in the respective subplot\n",
    "        axs[i].bar(pos - bar_width/2, scores_modelA, bar_width, label='GCN')\n",
    "        axs[i].bar(pos + bar_width/2, scores_modelB, bar_width, label='GAT')\n",
    "\n",
    "        # Adding labels and titles\n",
    "        axs[i].set_xlabel('Metrics')\n",
    "        axs[i].set_title(f'{phase.capitalize()} Metrics')\n",
    "        axs[i].set_xticks(pos)\n",
    "        axs[i].set_xticklabels(metric_names)\n",
    "\n",
    "        # Adding a legend to the first subplot\n",
    "        if i == 0:\n",
    "            axs[i].legend()\n",
    "\n",
    "    # Setting the main title and showing the plot\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "di6Zhiq0ds3p",
   "metadata": {
    "id": "di6Zhiq0ds3p"
   },
   "source": [
    "### Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hnPNAFYLFORu",
   "metadata": {
    "id": "hnPNAFYLFORu"
   },
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "## 1. Generate embeddings using the GCN model\n",
    "## 2. Generate embeddings using the GAT model\n",
    "## Note: use detach to avoid using the computation graph\n",
    "## convert the tensor to a numpy array\n",
    "## use H_GCN and H_GAT as variable names\n",
    "## (~2 lines of code)\n",
    "H_GCN = model_GCN(features).detach().cpu().numpy()\n",
    "H_GAT = model_GAT(features).detach().cpu().numpy()\n",
    "#########################################\n",
    "plot_embeddings(H_GCN,H_GAT, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qgz-LV0laj5U",
   "metadata": {
    "id": "qgz-LV0laj5U"
   },
   "source": [
    "Based on the visualizations in the plots, what insights can you gather about the embeddings generated by each model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PSbW4t-Ed6kr",
   "metadata": {
    "id": "PSbW4t-Ed6kr"
   },
   "source": [
    "######## Your response here (double-click) ########\n",
    "\n",
    "\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5NkRAVHefKI",
   "metadata": {
    "id": "b5NkRAVHefKI"
   },
   "source": [
    "### Distribution of learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcXWvuy0Yc7n",
   "metadata": {
    "id": "bcXWvuy0Yc7n"
   },
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "## 1. Extract the weights from the second graph\n",
    "## convolutional layer (gc2) of the GCN model\n",
    "## 2. Extract the weights from the second graph\n",
    "## convolutional layer (gc2) of the GAT model\n",
    "## Note: use detach to avoid using the computation graph\n",
    "## convert the tensor to a numpy array\n",
    "## use Omega_GCN_gc2 and Omega_GAT_gc2 as variable names\n",
    "## (~2 lines of code)\n",
    "Omega_GCN_gc2 = model_GCN.weight.data\n",
    "Omega_GAT_gc2 = model_GAT.weight.data\n",
    "#########################################\n",
    "plot_weight_distributions(Omega_GCN_gc2, Omega_GAT_gc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uffhAF6Ie9iD",
   "metadata": {
    "id": "uffhAF6Ie9iD"
   },
   "source": [
    "Reflect on the observed distributions of the weights from the models. What conclusions or understandings can be drawn about the behavior and characteristics of each model based on these distributions?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Poj0JkdBe9vV",
   "metadata": {
    "id": "Poj0JkdBe9vV"
   },
   "source": [
    "######## Your response here (double-click) ########\n",
    "\n",
    "\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WwhgePeTe4tK",
   "metadata": {
    "id": "WwhgePeTe4tK"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TjhJAM3GbkWW",
   "metadata": {
    "id": "TjhJAM3GbkWW"
   },
   "outputs": [],
   "source": [
    "metrics = {\"acc\": accuracy, \"sensitivity\": sensitivity, \"specifity\": specificity}\n",
    "results_GCN = test(model_GCN, features, adj,\n",
    "                   labels, train_mask, val_mask, test_mask, metrics)\n",
    "results_GAT = test(model_GAT, features, adj,\n",
    "                   labels, train_mask, val_mask, test_mask, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26gMjOincTMm",
   "metadata": {
    "id": "26gMjOincTMm"
   },
   "outputs": [],
   "source": [
    "plot_metrics([results_GCN, results_GAT], 'Metric Comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ArHRsbJ7gv9t",
   "metadata": {
    "id": "ArHRsbJ7gv9t"
   },
   "source": [
    "How might you interpret the outcomes of these results?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hWjw5eD7gmx7",
   "metadata": {
    "id": "hWjw5eD7gmx7"
   },
   "source": [
    "######## Your response here (double-click) ########\n",
    "\n",
    "\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qIc4lj0whLbW",
   "metadata": {
    "id": "qIc4lj0whLbW"
   },
   "source": [
    "## Bonus question 1\n",
    "\n",
    "What changes in the GCN and GAT layers would result in a more effective implementation?\n",
    "\n",
    "Hint: See how [message passing](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) is implemented in PyTorch Geometric.\n",
    "\n",
    "Furthermore, explore the specific implementations for [GCN](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GCNConv.html) and [GAT](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GATConv.html).\n",
    "\n",
    "*Note: Bonus questions are ungraded yet provide an opportunity for those who wish to delve deeper into their graph based learning journey.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q4uW3ekljtlQ",
   "metadata": {
    "id": "Q4uW3ekljtlQ"
   },
   "source": [
    "######## Your response here (double-click) ########\n",
    "\n",
    "\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahE7TBzSwKCt",
   "metadata": {
    "id": "ahE7TBzSwKCt"
   },
   "source": [
    "## Bonus question 2\n",
    "\n",
    "Write the kipf normalization\n",
    "\n",
    "$H_{k+1} = a[\\beta_k\\mathbf{1}^T + \\Omega_kH_k(D^{-1/2}AD^{-1/2}+I)]$\n",
    "\n",
    "*Note: Bonus questions are ungraded yet provide an opportunity for those who wish to delve deeper into their graph based learning journey.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IQ_VTX4Awo7n",
   "metadata": {
    "id": "IQ_VTX4Awo7n"
   },
   "outputs": [],
   "source": [
    "def kipf_normalization(A):\n",
    "  ############# Your code here ############\n",
    "\n",
    "  #########################################\n",
    "  return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gaf3LOV7c5O9",
   "metadata": {
    "id": "Gaf3LOV7c5O9"
   },
   "source": [
    "# 4) Propagation rule integrating edge features/embeddings (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aCStFPrA8rAD",
   "metadata": {
    "id": "aCStFPrA8rAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   0   0   0]\n",
      "  [  1   7  50 390]\n",
      "  [  1   5  44 323]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]\n",
      "\n",
      " [[  1   7  50 390]\n",
      "  [  0   0   0   0]\n",
      "  [  1   6  47 363]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]\n",
      "\n",
      " [[  1   5  44 323]\n",
      "  [  1   6  47 363]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  1   4  40 272]]\n",
      "\n",
      " [[  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  1   3  45 288]]\n",
      "\n",
      " [[  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  [  0   0   0   0]\n",
      "  ...\n",
      "  [  1   4  40 272]\n",
      "  [  1   3  45 288]\n",
      "  [  0   0   0   0]]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)  # Setting a fixed seed for numpy random number generator\n",
    "\n",
    "\n",
    "# we will create a stochastic block model graph with two communities and 20 nodes\n",
    "G = nx.stochastic_block_model(sizes=[10, 10], p=[[0.8, 0.1], [0.1, 0.8]], seed=seed)\n",
    "\n",
    "# We will create a node feature\n",
    "communities = nx.community.louvain_communities(G)\n",
    "X = np.zeros((len(G), 1))\n",
    "X[list(communities[0])] = 1\n",
    "\n",
    "A = nx.adjacency_matrix(G).todense()\n",
    "\n",
    "# we will use powers of the adjacency matrix as edge features (considering edge embeddings only on edges already existing)\n",
    "E1 = A\n",
    "E2 = (A @ A)*A # we zero the embedding on edges which aren't connected\n",
    "E3 = (A @ A @ A)*A\n",
    "E4 = (A @ A @ A @ A)*A\n",
    "\n",
    "E = np.stack((E1, E2, E3, E4), axis = 2)\n",
    "\n",
    "print(E)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3EPth4u885N-",
   "metadata": {
    "id": "3EPth4u885N-"
   },
   "source": [
    "### 4.1) Graph visualization <b>(5 points)</b>\n",
    "\n",
    "#### 4.1.1 Use networkx to visualize the structure and the node features of the graph. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "svQEBbzg8xX_",
   "metadata": {
    "id": "svQEBbzg8xX_"
   },
   "outputs": [],
   "source": [
    "def VisualizeGraphNetworkx(G):\n",
    "    '''\n",
    "    input: G\n",
    "    A networkx graph instance\n",
    "    '''\n",
    "    #Complete code here:\n",
    "    # Extract the feature values for each node into a list\n",
    "    feature_values = np.array([G.nodes[node]['feature'] for node in G.nodes])\n",
    "    \n",
    "    # Normalize the feature values to use for node color mapping\n",
    "    norm = plt.Normalize(vmin=feature_values.min(), vmax=feature_values.max())\n",
    "    node_colors = plt.cm.viridis(norm(feature_values))\n",
    "    \n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(G)  # You can choose different layouts like circular_layout, random_layout, etc.\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, cmap=plt.cm.viridis)\n",
    "    \n",
    "    # Add a color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=norm)\n",
    "    sm.set_array([])\n",
    "    plt.colorbar(sm, label='Feature Values')\n",
    "    ####################\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2BRqCmSV9CxU",
   "metadata": {
    "id": "2BRqCmSV9CxU"
   },
   "source": [
    "#### 4.1.2 Display the edge features for edges which are connected to node 0 (first node). (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "GAa3JxT79E_7",
   "metadata": {
    "id": "GAa3JxT79E_7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m''' code to display the edge features for all edges connected to node 0. List the output in the format\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m[node 0, node x, edge_features]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m[node 0, node y, edge_features] ...\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m Please change = None to your implementation.'''\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m edge_features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mneighbor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_features)\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m''' code to display the edge features for all edges connected to node 0. List the output in the format\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m[node 0, node x, edge_features]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m[node 0, node y, edge_features] ...\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m Please change = None to your implementation.'''\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m edge_features \u001b[38;5;241m=\u001b[39m [(\u001b[43mnode\u001b[49m, neighbor, E[node, neighbor, :]) \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(G\u001b[38;5;241m.\u001b[39mneighbors(\u001b[38;5;241m0\u001b[39m))]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_features)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'node' is not defined"
     ]
    }
   ],
   "source": [
    "''' code to display the edge features for all edges connected to node 0. List the output in the format\n",
    "[node 0, node x, edge_features]\n",
    "[node 0, node y, edge_features] ...\n",
    " Please change = None to your implementation.'''\n",
    "    \n",
    "edge_features = [(node, neighbor, E[node, neighbor, :]) for neighbor in list(G.neighbors(0))]\n",
    "print(edge_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqL_AF0m9JCD",
   "metadata": {
    "id": "oqL_AF0m9JCD"
   },
   "source": [
    "### 4.2 Mathematical Formulation <b>(5 points)</b>\n",
    "\n",
    "Consider a graph with node embedding $\\mathbf{h}_n$ based on its neighboring node embeddings $\\{\\mathbf{h}_m\\}_{m \\in ne[n]}$ and the neighboring edge embeddings $\\{\\mathbf{e}_m\\}_{m \\in nee[n]}$\n",
    "$ne[n]$ denotes the neighbors of node $n$ and $nee[n]$ denotes the edges connected to node $n$.\n",
    "  \n",
    "Let the update rule without accounting for edge embeddings is the following\n",
    "\n",
    "$\\mathbf{H}_{k+1} = a[ \\mathbf{\\beta}_k \\mathbf{1}^T + \\mathbf{\\Omega}_k \\mathbf{H}_k (\\mathbf{A} + \\mathbf{I}) ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0wTK6G6X9au5",
   "metadata": {
    "id": "0wTK6G6X9au5"
   },
   "source": [
    "#### 4.2.1 fill in the [...] in the equation below so that we account for edge embeddings (3 points)\n",
    "\n",
    "$\\mathbf{H}_{k+1} = a[ \\mathbf{\\beta}_k \\mathbf{1}^T + \\mathbf{\\Omega}_k \\mathbf{H}_k (\\mathbf{A} + \\mathbf{I}) + [...]]$  (1)\n",
    "\n",
    "$$\n",
    "H_{k+1} = \\alpha \\left( \\beta_k I^T + \\Omega_k H_k (A \\odot E) + \\Gamma_k E H_k (A + I) \\right) \n",
    "$$ \n",
    "new equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-o0WJog-9cYa",
   "metadata": {
    "id": "-o0WJog-9cYa"
   },
   "source": [
    "#### 4.2.2 Define any new variables you introduce in the matrix form of (1) and specify their size. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c7b8f",
   "metadata": {},
   "source": [
    "- $E$ is the edge embedding matrix, where $E_{ij}$ represents the embedding for the edge between nodes $i$ and $j$. The size of $E$ would be $|E| \\times d_e$, where $|E|$ is the number of edges and $d_e$ is the dimension of the edge embeddings.\n",
    "- $\\odot$ represents the Hadamard product (element-wise multiplication), which is used to apply the edge embeddings to the adjacency matrix.\n",
    "- $\\Gamma_k$ is a new transformation matrix that captures the interaction between edge embeddings and the node embeddings. Its size would be the same as $\\Omega_k$, so if $\\Omega_k$ is $d \\times d$ (where $d$ is the dimension of the node embeddings), then $\\Gamma_k$ would also be $d \\times d$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FO84ej4M9e9S",
   "metadata": {
    "id": "FO84ej4M9e9S"
   },
   "source": [
    "### 4.3) Implementation <b>(5 points)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "qtFGBFbG9h5B",
   "metadata": {
    "id": "qtFGBFbG9h5B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "np.random.seed(42)  # Setting a fixed seed for numpy random number generator\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def add_self_connections(A):\n",
    "    \"\"\"\n",
    "    Add self-connections to the adjacency matrix.\n",
    "\n",
    "    This function adds an identity matrix to the adjacency matrix `A`, which\n",
    "    effectively adds a self-loop to each node in the graph. This is a common\n",
    "    preprocessing step in graph neural network implementations.\n",
    "\n",
    "    Parameters:\n",
    "    A (np.ndarray): The adjacency matrix to modify.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The adjacency matrix with self-connections added.\n",
    "    \"\"\"\n",
    "    I = np.eye(A.shape[0])\n",
    "    return A + I\n",
    "\n",
    "\n",
    "def normalize_adjacency(A_hat):\n",
    "    \"\"\"\n",
    "    Normalize the adjacency matrix.\n",
    "\n",
    "    This function applies symmetric normalization to the adjacency matrix\n",
    "    `A_hat`. The normalization is done using the inverse square root of the\n",
    "    degree matrix. This step is important for many graph-based learning\n",
    "    algorithms to ensure that the scale of the feature representations is not\n",
    "    skewed by node degree.\n",
    "\n",
    "    Parameters:\n",
    "    A_hat (np.ndarray): The adjacency matrix with self-connections.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The normalized adjacency matrix.\n",
    "    \"\"\"\n",
    "    D_hat_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A_hat, axis=0)))\n",
    "    return D_hat_inv_sqrt.dot(A_hat).dot(D_hat_inv_sqrt)\n",
    "\n",
    "\n",
    "\n",
    "# GCN update steps\n",
    "A_hat = add_self_connections(A) # A is from question 1.2\n",
    "\n",
    "# define input features\n",
    "H_k = X\n",
    "\n",
    "# Define the dimensions of the weight matrix\n",
    "input_features = H_k.shape[1]  # Number of input features (columns of H_k)\n",
    "output_features = 2  # Number of output features (can be chosen based on your model's design)\n",
    "\n",
    "# Initialize the weight matrix Omega_k with random values\n",
    "Omega_k = np.random.rand(input_features, output_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkMfH2569lAo",
   "metadata": {
    "id": "QkMfH2569lAo"
   },
   "source": [
    "#### 4.1 Implement equation (1) and print out an update using this equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "oJasGBjZ9nX5",
   "metadata": {
    "id": "oJasGBjZ9nX5"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m Omega_k \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], output_features)\n\u001b[0;32m     35\u001b[0m Gamma_k \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(E\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], output_features)\n\u001b[1;32m---> 37\u001b[0m H_k_edge_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOmega_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGamma_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# H_k_edge_embeddings = None\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWith edge-embeddings:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, H_k_edge_embeddings)\n",
      "Cell \u001b[1;32mIn[28], line 29\u001b[0m, in \u001b[0;36mgcn_update\u001b[1;34m(H_k, A, E, Omega_k, Gamma_k)\u001b[0m\n\u001b[0;32m     26\u001b[0m sum_edge_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(A_E, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Assuming sum over the second axis (neighbors)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Update rule\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m H_k_plus_1 \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mOmega_k\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH_k\u001b[49m \u001b[38;5;241m+\u001b[39m Gamma_k \u001b[38;5;241m@\u001b[39m sum_edge_features)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H_k_plus_1\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 20 is different from 2)"
     ]
    }
   ],
   "source": [
    "''' Please implement your update which includes edge embeddings below (change = None)\n",
    "You should use A, X and E defined at the beginning of 4)\n",
    "\n",
    "'''\n",
    "def gcn_update(H_k, A, E, Omega_k, Gamma_k):\n",
    "    \"\"\"\n",
    "    Perform a GCN update step including edge embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    H_k (np.ndarray): Current node embeddings.\n",
    "    A (np.ndarray): Adjacency matrix with self-connections.\n",
    "    E (np.ndarray): Edge embedding tensor.\n",
    "    Omega_k (np.ndarray): Weight matrix for node features.\n",
    "    Gamma_k (np.ndarray): Weight matrix for edge embeddings.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Updated node embeddings.\n",
    "    \"\"\"\n",
    "    I = np.eye(A.shape[0])  # Identity matrix\n",
    "    A_with_self_loops = A + I\n",
    "    \n",
    "    # Hadamard product of A and E along the third dimension of E\n",
    "    A_E = np.einsum('ij,ijk->ijk', A, E)\n",
    "    \n",
    "    # Sum edge features for each node\n",
    "    sum_edge_features = np.sum(A_E, axis=1)  # Assuming sum over the second axis (neighbors)\n",
    "\n",
    "    # Update rule\n",
    "    H_k_plus_1 = sigmoid(Omega_k @ H_k + Gamma_k @ sum_edge_features)\n",
    "    \n",
    "    return H_k_plus_1\n",
    "\n",
    "# Example usage:\n",
    "Omega_k = np.random.rand(X.shape[1], output_features)\n",
    "Gamma_k = np.random.rand(E.shape[2], output_features)\n",
    "\n",
    "H_k_edge_embeddings = gcn_update(X, A, E, Omega_k, Gamma_k)\n",
    "\n",
    "# H_k_edge_embeddings = None\n",
    "\n",
    "print(\"\\nWith edge-embeddings:\\n\", H_k_edge_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eqEsEFp8c5O-",
   "metadata": {
    "id": "eqEsEFp8c5O-"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Yh_VUCCsc5O-",
   "metadata": {
    "id": "Yh_VUCCsc5O-"
   },
   "source": [
    "# 5) Bonus (5 points)\n",
    "\n",
    "#### Graph Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S0Fzftx0_kNV",
   "metadata": {
    "id": "S0Fzftx0_kNV"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# here we have two datasets of the same digits. One using pixels and the other in the Fourier Domain.\n",
    "\n",
    "# load digits in fourier domain\n",
    "df1 = pd.read_csv('sample_data/fourier.csv', header=None)\n",
    "X1 = df1.to_numpy()\n",
    "print(len(X1))\n",
    "\n",
    "# load digits in pixel domain\n",
    "df2 = pd.read_csv('sample_data/pixel.csv', header=None)\n",
    "X2 = df2.to_numpy()\n",
    "print(len(X2))\n",
    "\n",
    "\n",
    "# generate distances between all pairs of points to create distance matrix\n",
    "A1 = euclidean_distances(X1,X1)\n",
    "A2 = euclidean_distances(X2,X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2VRqe8vn_dPR",
   "metadata": {
    "id": "2VRqe8vn_dPR"
   },
   "source": [
    "Here we have two graphs $G =(A1,X1)$ and $G' = (A2,X2)$ representating the same dataset in different domains.\n",
    "\n",
    "#### 5.1) Use the SNF graph cross-diffusion rule (see equations (4) and (5) in the SNF paper) to define a function $G_f = fuse(G,G')$ that fuses the node and edge features of these two graphs. Formalize the solution mathematically in the matrix form (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_GCv6arK_dnL",
   "metadata": {
    "id": "_GCv6arK_dnL"
   },
   "source": [
    "answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bj2SPVR9_dq0",
   "metadata": {
    "id": "Bj2SPVR9_dq0"
   },
   "source": [
    "#### 5.2) Cross-diffuse graphs G and G' above using your new formula. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2UREw95M_dy7",
   "metadata": {
    "id": "2UREw95M_dy7"
   },
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(X, mu, epsilon):\n",
    "    \"\"\"\n",
    "    Compute the similarity matrix using the scaled exponential similarity kernel.\n",
    "    \"\"\"\n",
    "    # Compute pairwise Euclidean distances\n",
    "    distances = euclidean_distances(X, X)\n",
    "    \n",
    "    # Apply the scaled exponential similarity kernel\n",
    "    W = np.exp(-np.power(distances, 2) / (mu * epsilon))\n",
    "    \n",
    "    return W\n",
    "\n",
    "def normalize_similarity_matrix(W):\n",
    "    \"\"\"\n",
    "    Normalize the similarity matrix.\n",
    "    \"\"\"\n",
    "    P = np.zeros_like(W)\n",
    "    for i in range(W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            if i != j:\n",
    "                P[i, j] = W[i, j] / (2 * np.sum(W[i, :]))\n",
    "            else:\n",
    "                P[i, i] = 1 / 2\n",
    "    return P\n",
    "\n",
    "def knn_similarity(W, k):\n",
    "    \"\"\"\n",
    "    Compute the kernel matrix using KNN.\n",
    "    \"\"\"\n",
    "    S = np.zeros_like(W)\n",
    "    for i in range(W.shape[0]):\n",
    "        neighbors = np.argsort(-W[i, :])[:k+1]  # Including self\n",
    "        S[i, neighbors] = W[i, neighbors] / np.sum(W[i, neighbors])\n",
    "    return S\n",
    "\n",
    "def snf(S1, S2, num_iterations):\n",
    "    \"\"\"\n",
    "    Apply Similarity Network Fusion (SNF) to two kernel matrices.\n",
    "    \"\"\"\n",
    "    P1 = np.copy(S1)\n",
    "    P2 = np.copy(S2)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        P1_new = S1 @ P2 @ S1.T\n",
    "        P2_new = S2 @ P1 @ S2.T\n",
    "        P1, P2 = P1_new, P2_new\n",
    "    \n",
    "    # Compute the final fused similarity matrix\n",
    "    P_c = (P1 + P2) / 2\n",
    "    return P_c\n",
    "\n",
    "# Usage:\n",
    "# Compute similarity matrices for both data types\n",
    "W1 = compute_similarity_matrix(X1, mu, epsilon1)\n",
    "W2 = compute_similarity_matrix(X2, mu, epsilon2)\n",
    "\n",
    "# Normalize the similarity matrices\n",
    "P1 = normalize_similarity_matrix(W1)\n",
    "P2 = normalize_similarity_matrix(W2)\n",
    "\n",
    "# Compute the kernel matrices using KNN\n",
    "S1 = knn_similarity(W1, k)\n",
    "S2 = knn_similarity(W2, k)\n",
    "\n",
    "# Apply Similarity Network Fusion\n",
    "P_c = snf(S1, S2, num_iterations=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3YOZHLJc5O-",
   "metadata": {
    "id": "f3YOZHLJc5O-"
   },
   "source": [
    "#### References:\n",
    "1. SNF paper: Wang, Bo, et al. \"Similarity network fusion for aggregating data types on a genomic scale.\" Nature methods 11.3 (2014): 333-337.\n",
    "2. Feel free to check  <A Href=\"https://www.youtube.com/watch?v=Oqrjkm6TIy8&list=PLug43ldmRSo3MV-Jgjr30E5SpwNKkjTvJ&index=32\">video</A> from minute 21 to 30 (9 minutes to cover)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "LQ7SGGtic5O6"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
